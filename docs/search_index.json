[["index.html", "Advanced Data Analysis in R and Python Preface Contact the Author", " Advanced Data Analysis in R and Python Hamilkar Constantin Oueslati 2023-03-29 Preface This book shall document my efforts in learning different methods used in the analysis of psychological data. Since this book was created at the beginning of my master’s programme in psychology at the University of Constance (winter of 2022), this book will only include methods, that were taught to me (by myself or others) during the course of said master’s programme. Contact the Author In case you wish to contact me, please use the following contact details: Hamilkar Constantin Oueslati Pronouns: they/them (engl.) and dey/deren/denen (ger.) Graduate Student at the University of Konstanz Study Programme: Psychology (M.Sc.) Mail: hamilkar-constantin.oueslati@uni-konstanz.de Web: https://hco-consulting.eu "],["prerequisites.html", "Chapter 1 Prerequisites 1.1 System Information 1.2 Configure Chunk Options 1.3 Load R Packages 1.4 Load Python 1.5 Import Python Modules 1.6 Manage References 1.7 Pandoc Filters", " Chapter 1 Prerequisites 1.1 System Information This Web Book was created on a platform running under macOS Ventura 13.2.1. 1.2 Configure Chunk Options knitr::opts_chunk$set(echo = TRUE, out.width = &quot;100%&quot;) 1.3 Load R Packages library(devtools) library(remotes) library(knitr) library(dplyr) library(tidyr) library(tidyverse) library(broom) library(broom.mixed) library(ggplot2) library(ggpubr) library(mclust) library(psych) library(cat) library(gridExtra) library(plotly) library(processx) library(reticulate) library(DiagrammeR) library(performance) library(afex) library(qqplotr) library(bookdown) library(FFTrees) library(rpart) library(rpart.plot) library(binom) library(rjags) library(BayesianFirstAid) library(rstatix) library(AICcmodavg) library(BayesFactor) library(emmeans) library(stanova) library(rstanarm) library(rstan) library(coda) library(StanHeaders) library(brms) library(caret) library(bayesplot) library(bayesrules) library(tidybayes) library(janitor) library(tibble) library(glue) library(RefManageR) library(rmarkdown) 1.4 Load Python use_python(&quot;/Library/Frameworks/Python.framework/Versions/3.11/bin/python3&quot;) 1.5 Import Python Modules import sys import numpy as np import matplotlib.pyplot as plt import pandas as pd import statsmodels.api as sm import statsmodels.formula.api as smf import statsmodels.stats.api as sms import statsmodels.stats.descriptivestats as smds from statsmodels.graphics.tsaplots import plot_acf from kneed import KneeLocator from sklearn.cluster import KMeans from sklearn.metrics import silhouette_score from sklearn.preprocessing import StandardScaler from sklearn import tree from sklearn.datasets import load_iris from chart_studio.plotly import plot, iplot import plotly.express as px import plotly.io as pio import plotly.graph_objects as go from plotly.subplots import make_subplots import scipy.stats as st import seaborn as sns from collections import Counter 1.6 Manage References write_bib(.packages(), &quot;r_packages.bib&quot;) cite_r_rstudio &lt;- function(cat_output = FALSE, write_bib_file = FALSE){ cite_r &lt;- as.BibEntry(citation()) r_version &lt;- paste(strsplit(version[[&#39;version.string&#39;]], &#39; &#39;)[[1]][3], strsplit(version[[&#39;version.string&#39;]], &#39; &#39;)[[1]][4], sep = &quot; &quot;) r_studio &lt;- RStudio.Version() cite_r_studio &lt;- as.BibEntry(r_studio$citation) r_studio_version &lt;- r_studio$long_version r_studio_name &lt;- r_studio$release_name frameline &lt;- strrep(&quot;-&quot;, 50) output &lt;- glue( r&quot;[ {frameline} R Version: {r_version} {frameline} RStudio Version: {r_studio_name} - {r_studio_version} {frameline} ]&quot;) if (cat_output){cat(output)} bib_entries &lt;- list(cite_r,cite_r_studio) names(bib_entries) &lt;- c(&quot;Bib Entry for &#39;R&#39;&quot;, &quot;Bib Entry for &#39;RStudio&#39;&quot;) if (write_bib_file){ WriteBib(c(bib_entries$`Bib Entry for &#39;R&#39;`, bib_entries$`Bib Entry for &#39;RStudio&#39;`), file = &quot;r_references.bib&quot;) } invisible(bib_entries) } cite_r_rstudio(cat_output = FALSE, write_bib_file = TRUE) numpy_bib &lt;- GetBibEntryWithDOI(&quot;10.1038/s41586-020-2649-2&quot;) matplotlib_bib &lt;- GetBibEntryWithDOI(&quot;10.1109/MCSE.2007.55&quot;) pandas_bib &lt;- GetBibEntryWithDOI(&quot;10.25080/Majora-92bf1922-00a&quot;) statsmodels_bib &lt;- as.BibEntry( c(bibtype = &quot;inproceedings&quot;, key = &quot;seabold2010statsmodels&quot;, title = &quot;statsmodels: Econometric and statistical modeling with python&quot;, author = &quot;Skipper Seabold and Josef Perktold&quot;, booktitle = &quot;9th Python in Science Conference&quot;, year = &quot;2010&quot;)) kneed_bib &lt;- GetBibEntryWithDOI(&quot;10.1109/ICDCSW.2011.20&quot;) sklearn_bib &lt;- as.BibEntry( c(bibtype = &quot;Article&quot;, key = &quot;scikit-learn&quot;, title = &quot;Scikit-learn: Machine Learning in {P}ython}&quot;, author = &quot;F. Pedregosa and G. Varoquaux and A. Gramfort and V.Michel and B. Thirion and O. Grisel and M. Blondel and P. Prettenhofer and R. Weiss and V. Dubourg and J. Vanderplas and A. Passos and D. Cournapeau and M. Brucher and M. Perrot and E. Duchesnay&quot;, journal = &quot;Journal of Machine Learning Research&quot;, volume = &quot;12&quot;, pages = &quot;2825--2830&quot;, year = &quot;2011&quot;)) plotly_bib &lt;- as.BibEntry( c(bibtype = &quot;Online&quot;, key = &quot;plotly&quot;, title = &quot;Collaborative data science&quot;, author = &quot;Plotly Technologies Inc.&quot;, publisher = &quot;Plotly Technologies Inc.&quot;, adress = &quot;Montreal, QC&quot;, year = &quot;2015&quot;, url = &quot;https://plot.ly&quot;)) scipy_bib &lt;- GetBibEntryWithDOI(&quot;10.1038/s41592-019-0686-2&quot;) seaborn_bib &lt;- GetBibEntryWithDOI(&quot;10.21105/joss.03021&quot;) WriteBib(c(numpy_bib, matplotlib_bib, pandas_bib, statsmodels_bib, kneed_bib, sklearn_bib, plotly_bib, scipy_bib, seaborn_bib), file = &quot;python_packages.bib&quot;) python_version = &quot;.&quot;.join(map(str, sys.version_info[:3])) cite_python &lt;- function(cat_output = FALSE, write_bib_file = FALSE){ python_bib &lt;- as.BibEntry( c(bibtype = &quot;Article&quot;, key = &quot;python1991&quot;, title = &quot;Interactively testing remote servers using the Python programming language&quot;, author = &quot;Guido van Rossum and Jelke de Boer&quot;, journal = &quot;CWI Quarterly&quot;, volume = &quot;4&quot;, number = &quot;4&quot;, pages = &quot;283--304&quot;, year = &quot;1991&quot;, month = &quot;dec&quot;)) if (write_bib_file){ WriteBib(python_bib, file = &quot;python_reference.bib&quot;) } frameline &lt;- strrep(&quot;-&quot;, 25) output &lt;- glue( r&quot;[ {frameline} Python Version: {py$python_version} {frameline} ]&quot;) if (cat_output){cat(output)} invisible(python_bib) } cite_python(cat_output = FALSE, write_bib_file = TRUE) 1.7 Pandoc Filters Some lua filters do no work with the Pandoc version bundled with RStudio. Due to that I installed a separate Pandoc version. For more information see the Pandoc installation guide. In order to render documents using a different version of Pandoc one must supply the rmarkdown package with the path of the Pandoc executable by calling the function rmarkdown::find_pandoc(). Find the Pandoc executable by inputting which pandoc in the Terminal. find_pandoc(cache = FALSE) ## $version ## [1] &#39;3.1.2&#39; ## ## $dir ## [1] &quot;/usr/local/bin&quot; find_pandoc(dir = &quot;/usr/local/bin/pandoc&quot;) ## $version ## [1] &#39;3.1.2&#39; ## ## $dir ## [1] &quot;/usr/local/bin&quot; Save Lua filters to the filters directory of Pandoc’s user data directory. One can get the path to the user data directory with pandoc -v. After installation of Pandoc usually neither the filters nor the user data directory exist. Create the filters directory by inputting mkdir -p ~/.local/share/pandoc/filters in the Terminal. 1.7.1 Enable Multiple Bibliographies The following code chunk writes the Lua filter by Albert Krewinkel to a Lua file within the filters directory mentioned above using the cat engine. Alternatively one could just copy and save the code manually using any other code editor. For more information and a whole host of useful filters see the Pandoc Lua filters GitHub repository. # ```{cat engine.opts = list(file = &quot;/Users/constantine/.local/share/pandoc/filters/multiple-bibliographies.lua&quot;)} # --[[ # multiple-bibliographies – create multiple bibliographies # Copyright © 2018-2021 Albert Krewinkel # Permission to use, copy, modify, and/or distribute this software for any # purpose with or without fee is hereby granted, provided that the above # copyright notice and this permission notice appear in all copies. # THE SOFTWARE IS PROVIDED &quot;AS IS&quot; AND THE AUTHOR DISCLAIMS ALL WARRANTIES # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF # MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR # ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES # WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN # ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF # OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. # ]] # local List = require &#39;pandoc.List&#39; # local utils = require &#39;pandoc.utils&#39; # local stringify = utils.stringify # local run_json_filter = utils.run_json_filter # # --- Collection of all cites in the document # local all_cites = {} # --- Document meta value # local doc_meta = pandoc.Meta{} # # --- Div used by pandoc-citeproc to insert the bibliography. # local refs_div = pandoc.Div({}, pandoc.Attr(&#39;refs&#39;)) # # -- Div filled by citeproc with properties set according to # -- the output format and the attributes of cs:bibliography # local refs_div_with_properties # # local supports_quiet_flag = (function () # -- We use pandoc instead of pandoc-citeproc starting with pandoc 2.11 # if PANDOC_VERSION &gt;= &quot;2.11&quot; then # return true # end # local version = pandoc.pipe(&#39;pandoc-citeproc&#39;, {&#39;--version&#39;}, &#39;&#39;) # local major, minor, patch = version:match &#39;pandoc%-citeproc (%d+)%.(%d+)%.?(%d*)&#39; # major, minor, patch = tonumber(major), tonumber(minor), tonumber(patch) # return major &gt; 0 # or minor &gt; 14 # or (minor == 14 and patch &gt;= 5) # end)() # # local function run_citeproc(doc, quiet) # if PANDOC_VERSION &gt;= &quot;2.11&quot; then # return run_json_filter( # doc, # &#39;pandoc&#39;, # {&#39;--from=json&#39;, &#39;--to=json&#39;, &#39;--citeproc&#39;, quiet and &#39;--quiet&#39; or nil} # ) # else # -- doc = run_json_filter(doc, &#39;pandoc-citeproc&#39;) # return run_json_filter( # doc, # &#39;pandoc-citeproc&#39;, # {FORMAT, (quiet and supports_quiet_flag) and &#39;-q&#39; or nil} # ) # end # end # # # --- Resolve citations in the document by combining all bibliographies # -- before running pandoc-citeproc on the full document. # local function resolve_doc_citations (doc) # -- combine all bibliographies # local meta = doc.meta # local orig_bib = meta.bibliography # meta.bibliography = pandoc.MetaList{orig_bib} # for name, value in pairs(meta) do # if name:match(&#39;^bibliography_&#39;) then # table.insert(meta.bibliography, value) # end # end # -- add dummy div to catch the created bibliography # table.insert(doc.blocks, refs_div) # -- resolve all citations # -- doc = run_json_filter(doc, &#39;pandoc-citeproc&#39;) # doc = run_citeproc(doc) # -- remove catch-all bibliography and keep it for future use # refs_div_with_properties = table.remove(doc.blocks) # -- restore bibliography to original value # doc.meta.bibliography = orig_bib # return doc # end # # --- Explicitly create a new meta object with all fields relevant for # --- pandoc-citeproc. # local function meta_for_pandoc_citeproc (bibliography) # -- We could just indiscriminately copy all meta fields, but let&#39;s be # -- explicit about what&#39;s important. # local fields = { # &#39;bibliography&#39;, &#39;references&#39;, &#39;csl&#39;, &#39;citation-style&#39;, # &#39;link-citations&#39;, &#39;citation-abbreviations&#39;, &#39;lang&#39;, # &#39;suppress-bibliography&#39;, &#39;reference-section-title&#39;, # &#39;notes-after-punctuation&#39;, &#39;nocite&#39; # } # local new_meta = pandoc.Meta{} # for _, field in ipairs(fields) do # new_meta[field] = doc_meta[field] # end # new_meta.bibliography = bibliography # return new_meta # end # # local function remove_duplicates(classes) # local seen = {} # return classes:filter(function(x) # if seen[x] then # return false # else # seen[x] = true # return true # end # end) # end # # --- Create a bibliography for a given topic. This acts on all divs whose # -- ID starts with &quot;refs&quot;, followed by nothing but underscores and # -- alphanumeric characters. # local function create_topic_bibliography (div) # local name = div.identifier:match(&#39;^refs([_%w]*)$&#39;) # local bibfile = name and doc_meta[&#39;bibliography&#39; .. name] # if not bibfile then # return nil # end # local tmp_blocks = {pandoc.Para(all_cites), refs_div} # local tmp_meta = meta_for_pandoc_citeproc(bibfile) # local tmp_doc = pandoc.Pandoc(tmp_blocks, tmp_meta) # local res = run_citeproc(tmp_doc, true) -- try to be quiet # -- First block of the result contains the dummy paragraph, second is # -- the refs Div filled by pandoc-citeproc. # div.content = res.blocks[2].content # -- Set the classes and attributes as pandoc-citeproc did it on refs_div # div.classes = remove_duplicates(refs_div_with_properties.classes) # div.attributes = refs_div_with_properties.attributes # return div # end # # return { # { # -- Collect all citations and the doc&#39;s Meta value for other filters. # Cite = function (c) all_cites[#all_cites + 1] = c end, # Meta = function (m) doc_meta = m end, # }, # { Pandoc = resolve_doc_citations }, # { Div = create_topic_bibliography }, # } #``` Before being able to use a Lua filter one needs to make the appropriate adjustments to the YAML metadata. For more information see chapter 5.1.2 of the R Markdown Cookbook (Xie et al., 2022). "],["bayesian-statistics.html", "Chapter 2 Bayesian Statistics 2.1 Bayesian Basics 2.2 Markov Chain Monte Carlo Methods 2.3 Bayesian Decision Theory", " Chapter 2 Bayesian Statistics In the course of my bachelor studies in psychology I was mainly taught the frequentist approach to conducting statistical analyses. Therefore I decided to expand my knowledge regarding Bayesian statistics in the course of my master studies. In this chapter you will find examples of several statistical analyses, which I conducted using the Bayesian approach, rather than the frequentist approach. Said analyses were part of an assignment in a course titled “Introduction to Bayesian-Statistics for Psychologists” held by Prof. Dr. Fridtjof Nussbeck in the winter semester of 2022/23. This chapter also includes a very brief introduction to Markov Chain Monte Carlo Methods as well as more detailed practical introduction to Bayesian Decision Theory. These too were part of the same course assignment mentioned above. 2.1 Bayesian Basics 2.1.1 Binomial Test Research Question: Are the sentiments of tweets written by users from New York during the Delta Covid wave (January 2020 - October 2021) differently distributed than the sentiments of tweets written by users from Toronto in the same time period? # load datasets ny_tweets &lt;- read.csv(&quot;Data/new_york_scores.csv&quot;, row.names = NULL) ny_tweets &lt;- ny_tweets[, -4] colnames(ny_tweets) &lt;- c(&quot;ID&quot;, &quot;Date&quot;, &quot;Text&quot;, &quot;Sentiment&quot;, &quot;Score&quot;) ny_tweets$`City of Origin` &lt;- rep(&quot;New York&quot;, length(ny_tweets$ID)) ny_tweets$`City of Origin` &lt;- as.factor(ny_tweets$`City of Origin`) ny_tweets$Sentiment &lt;- as.factor(ny_tweets$Sentiment) toronto_tweets &lt;- read.csv(&quot;Data/toronto_scores.csv&quot;, row.names = NULL) toronto_tweets &lt;- toronto_tweets[, -4] colnames(toronto_tweets) &lt;- c(&quot;ID&quot;, &quot;Date&quot;, &quot;Text&quot;, &quot;Sentiment&quot;, &quot;Score&quot;) toronto_tweets$`City of Origin` &lt;- rep(&quot;Toronto&quot;, length(toronto_tweets$ID)) toronto_tweets$`City of Origin` &lt;- as.factor(toronto_tweets$`City of Origin`) toronto_tweets$Sentiment &lt;- as.factor(toronto_tweets$Sentiment) tweets &lt;- bind_rows(ny_tweets, toronto_tweets) # inspect datasets head(ny_tweets) ## ID Date ## 1 0 2020-09-20 ## 2 1 2020-09-12 ## 3 2 2020-09-12 ## 4 3 2020-09-17 ## 5 4 2020-09-20 ## 6 5 2020-09-09 ## Text ## 1 @MZHemingway According to Dementia Joe, between Covid and gun violence, no Americans survive.\\n\\nhttps://t.co/ggYvfytroc ## 2 Forget Covid, cold-season DURING Covid is actually unbearable. Do I have a cold, is it allergies, or am I dying? I need answers https://t.co/TPXx95pnCf ## 3 I need to get back in the cadence of writing. This COVID craziness is throwing off all sorts of rhythms. BUT! Im back at #amquerying so thats something :) Making #Zavaliv dream a reality email by email! Maybe Book 2 coming soon :) #novel ## 4 @angelahaupt @usnews @drbreenheroes @timkaine @theNAMedicine Experts are calling on hospitals, medical schools and the highest levels of government to do more to safeguard the well-being of front-line health providers as the pandemic stretches on with no end in sight. #SuicidePrevention #physicianburnout #NPSADay ## 5 @ishsmish @alisyaxo It was the pandemic. Everyones been going through it ## 6 @brianrayguitar Its a pretty serious side effect if it was caused by the vaccine . ## Sentiment Score City of Origin ## 1 0 50.33 New York ## 2 0 89.42 New York ## 3 1 94.46 New York ## 4 0 87.20 New York ## 5 0 78.51 New York ## 6 0 88.02 New York head(toronto_tweets) ## ID Date ## 1 0 10/31/2021 ## 2 1 10/31/2021 ## 3 2 10/31/2021 ## 4 3 10/31/2021 ## 5 4 10/31/2021 ## 6 5 10/31/2021 ## Text ## 1 \\n&quot;Rickards, aveteran who served three tours in Afghanistan with the Canadian Armed Forces, stood waiting. Finally, the man he&#39;d spent years trying to bring to Canadawalked through the doors with a smile that could be seen through his mask.&quot;\\n\\nhttps://t.co/96CtVfvB8u ## 2 Fuck.\\n\\n&quot;White House press secretary Jen Psaki, who dropped off President Joe Biden&#39;s international trip shortly before he departed, has tested positive for coronavirus.&quot;\\nhttps://t.co/EEJg0MLJPN ## 3 @GillianMcKeith I have no sympathy you are a nurse. Your job is to help sick people get healthy. You are a disgrace to nursing profession. Think about the sick patients who can die if exposed to the virus. The vaccine gives body protection from Covid. Shame on you lady! ## 4 @TravelEater Im not even elected but given the pandemic is still a real thing I would not leave the country without my employers knowledge and prior approval. Even though the G of C has changed its statement on travel. I just asked about what ministers would do. Im not assailing anyone. ## 5 @TravelEater Do you mean are there constraints in place preventing politicians from taking personal travel to other countries right now? I dont know. A government could impose those on their ministers and there might be a cabinet decree given pandemic is still on ## 6 @Zerpent2 Keep venting. Venting is good. I havent been able to read a single book the entire pandemic. And I like books. ## Sentiment Score City of Origin ## 1 1 94.82 Toronto ## 2 0 88.96 Toronto ## 3 1 51.09 Toronto ## 4 1 95.83 Toronto ## 5 0 66.38 Toronto ## 6 0 83.82 Toronto ## histograms - distribution of tweet sentiments tweets %&gt;% group_by(`City of Origin`) %&gt;% do(tweet_hist = plot_ly(., x = ~Sentiment, name = ~`City of Origin`, color = ~`City of Origin`, colors = c(&quot;#f4cccc&quot;, &quot;#c0d6e4&quot;), type = &quot;histogram&quot;, hovertemplate = paste(&quot;&lt;b&gt;Count&lt;/b&gt;: %{y}&quot;, &quot;&lt;br&gt;&lt;b&gt;Sentiment&lt;/b&gt;: %{x}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;)) %&gt;% layout(yaxis = list(title = &quot;Number of Tweets (#)&quot;))) %&gt;% subplot(nrows = 1, shareX = TRUE, shareY = TRUE) %&gt;% layout(title = &quot;Distribution of Tweet Sentiments&quot;, legend = list(title = list(text = &quot;&lt;b&gt; City of Origin &lt;/b&gt;&quot;)), margin = list(l = 75, r = 75, b = 75, t = 75)) # install and load packages needed for main # analysis install.packages(&#39;binom&#39;) # library(binom) # prepare analysis: define number of # &#39;successes&#39;, &#39;failures&#39; and observations one_ny = sum(with(ny_tweets, Sentiment == &quot;1&quot;)) zero_ny = sum(with(ny_tweets, Sentiment == &quot;0&quot;)) obs_ny = one_ny + zero_ny one_toronto = sum(with(toronto_tweets, Sentiment == &quot;1&quot;)) zero_toronto = sum(with(toronto_tweets, Sentiment == &quot;0&quot;)) obs_toronto = one_toronto + zero_toronto # calculate binomial confidence intervals (using # &#39;highest probability density&#39; aka &#39;hpd&#39;) hpd_ny.tweet.sentiment &lt;- binom.bayes(x = one_ny, n = obs_ny, type = &quot;highest&quot;, conf.level = 0.95, tol = 1e-09) hpd_toronto.tweet.sentiment &lt;- binom.bayes(x = one_toronto, n = obs_toronto, type = &quot;highest&quot;, conf.level = 0.95, tol = 1e-09) hpd_ny.tweet.sentiment ## method x n shape1 shape2 mean ## 1 bayes 10089 21000 10089.5 10911.5 0.4804295 ## lower upper sig ## 1 0.4736731 0.487187 0.05 hpd_toronto.tweet.sentiment ## method x n shape1 shape2 mean ## 1 bayes 8842 18477 8842.5 9635.5 0.4785421 ## lower upper sig ## 1 0.4713404 0.485745 0.05 # density plots binom.bayes.densityplot(hpd_ny.tweet.sentiment) binom.bayes.densityplot(hpd_toronto.tweet.sentiment) The calculated binomial confidence intervals overlap considerably. Thus we can conclude, that the distribution of sentiments of tweets written by users from New York between January 2020 and October 2021, does not differ from the distribution of sentiments of tweets written by users from Toronto in the same time period. 2.1.2 Independent t-Test Research Question: Do the IMDB scores of thriller films significantly differ from the IMDB scores of comedy films? # load dataset netflix_originals &lt;- read.csv(&quot;Data/NetflixOriginals.csv&quot;) # inspect dataset head(netflix_originals) ## Title Genre ## 1 Enter the Anime Documentary ## 2 Dark Forces Thriller ## 3 The App Science fiction/Drama ## 4 The Open House Horror thriller ## 5 Kaali Khuhi Mystery ## 6 Drive Action ## Premiere Runtime IMDB.Score ## 1 August 5, 2019 58 2.5 ## 2 August 21, 2020 81 2.6 ## 3 December 26, 2019 79 2.6 ## 4 January 19, 2018 94 3.2 ## 5 October 30, 2020 90 3.4 ## 6 November 1, 2019 147 3.5 ## Language ## 1 English/Japanese ## 2 Spanish ## 3 Italian ## 4 English ## 5 Hindi ## 6 Hindi netflix_originals %&gt;% count(Genre) ## Genre n ## 1 Action 7 ## 2 Action comedy 5 ## 3 Action thriller 1 ## 4 Action-adventure 1 ## 5 Action-thriller 3 ## 6 Action/Comedy 1 ## 7 Action/Science fiction 1 ## 8 Adventure 2 ## 9 Adventure-romance 1 ## 10 Adventure/Comedy 1 ## 11 Aftershow / Interview 6 ## 12 Animated musical comedy 1 ## 13 Animation 5 ## 14 Animation / Comedy 1 ## 15 Animation / Musicial 1 ## 16 Animation / Science Fiction 1 ## 17 Animation / Short 4 ## 18 Animation/Christmas/Comedy/Adventure 1 ## 19 Animation/Comedy/Adventure 1 ## 20 Animation/Musical/Adventure 1 ## 21 Animation/Superhero 1 ## 22 Anime / Short 1 ## 23 Anime/Fantasy 1 ## 24 Anime/Science fiction 2 ## 25 Anthology/Dark comedy 1 ## 26 Biographical/Comedy 1 ## 27 Biopic 9 ## 28 Black comedy 2 ## 29 Christian musical 1 ## 30 Christmas comedy 1 ## 31 Christmas musical 1 ## 32 Christmas/Fantasy/Adventure/Comedy 1 ## 33 Comedy 49 ## 34 Comedy / Musical 2 ## 35 Comedy horror 1 ## 36 Comedy mystery 1 ## 37 Comedy-drama 14 ## 38 Comedy/Fantasy/Family 1 ## 39 Comedy/Horror 1 ## 40 Coming-of-age comedy-drama 1 ## 41 Concert Film 6 ## 42 Crime drama 11 ## 43 Crime thriller 1 ## 44 Dance comedy 1 ## 45 Dark comedy 2 ## 46 Documentary 159 ## 47 Drama 77 ## 48 Drama / Short 1 ## 49 Drama-Comedy 1 ## 50 Drama/Horror 1 ## 51 Family 2 ## 52 Family film 2 ## 53 Family/Christmas musical 1 ## 54 Family/Comedy-drama 1 ## 55 Fantasy 1 ## 56 Heist 1 ## 57 Heist film/Thriller 1 ## 58 Hidden-camera prank comedy 1 ## 59 Historical drama 1 ## 60 Historical-epic 1 ## 61 Horror 9 ## 62 Horror anthology 1 ## 63 Horror comedy 1 ## 64 Horror thriller 3 ## 65 Horror-thriller 2 ## 66 Horror/Crime drama 1 ## 67 Making-of 2 ## 68 Mentalism special 1 ## 69 Mockumentary 2 ## 70 Musical 2 ## 71 Musical / Short 1 ## 72 Musical comedy 2 ## 73 Musical/Western/Fantasy 1 ## 74 Mystery 2 ## 75 One-man show 3 ## 76 Political thriller 1 ## 77 Psychological horror 1 ## 78 Psychological thriller 4 ## 79 Psychological thriller drama 1 ## 80 Romance 6 ## 81 Romance drama 1 ## 82 Romantic comedy 39 ## 83 Romantic comedy-drama 1 ## 84 Romantic comedy/Holiday 1 ## 85 Romantic drama 5 ## 86 Romantic teen drama 1 ## 87 Romantic teenage drama 1 ## 88 Romantic thriller 1 ## 89 Satire 2 ## 90 Science fiction 4 ## 91 Science fiction adventure 1 ## 92 Science fiction thriller 1 ## 93 Science fiction/Action 1 ## 94 Science fiction/Drama 3 ## 95 Science fiction/Mystery 1 ## 96 Science fiction/Thriller 4 ## 97 Sports film 1 ## 98 Sports-drama 3 ## 99 Spy thriller 2 ## 100 Stop Motion 1 ## 101 Superhero 2 ## 102 Superhero-Comedy 1 ## 103 Superhero/Action 1 ## 104 Supernatural drama 1 ## 105 Teen comedy horror 1 ## 106 Teen comedy-drama 1 ## 107 Thriller 33 ## 108 Urban fantasy 1 ## 109 Variety show 4 ## 110 Variety Show 1 ## 111 War 2 ## 112 War drama 2 ## 113 War-Comedy 1 ## 114 Western 3 ## 115 Zombie/Heist 1 ## violin plots - distribution of IMDB scores no_plot_df &lt;- filter(netflix_originals, Genre == &quot;Comedy&quot; | Genre == &quot;Thriller&quot;) netflix_violin_plot &lt;- no_plot_df %&gt;% plot_ly(x = ~Genre, y = ~IMDB.Score, split = ~Genre, type = &quot;violin&quot;, box = list(visible = T), meanline = list(visible = T), color = ~Genre, colors = c(&quot;#f4cccc&quot;, &quot;#c0d6e4&quot;)) netflix_violin_plot &lt;- netflix_violin_plot %&gt;% layout(title = &quot;Distribution of IMDB Scores&quot;, xaxis = list(title = &quot;Genre&quot;), yaxis = list(title = &quot;IMDB Score&quot;, zeroline = F), showlegend = FALSE, margin = list(l = 75, r = 75, b = 75, t = 75)) netflix_violin_plot # install and load programs and packages needed # for main analysis install JAGS info --&gt; # https://mcmc-jags.sourceforge.io packages --&gt; # https://sourceforge.net/projects/mcmc-jags/files/ # install.packages(&#39;rjags&#39;) library(rjags) # devtools::install_github(&#39;rasmusab/bayesian_first_aid&#39;) # library(BayesianFirstAid) # calculate independent t-test thriller_imdb_scores &lt;- netflix_originals$IMDB.Score[netflix_originals$Genre == &quot;Thriller&quot;] comedy_imdb_scores &lt;- netflix_originals$IMDB.Score[netflix_originals$Genre == &quot;Comedy&quot;] bayttest_analysis_thriller_comedy &lt;- bayes.t.test(thriller_imdb_scores, comedy_imdb_scores) ## | | | 0% | |* | 2% | |** | 4% | |*** | 6% | |**** | 8% | |***** | 10% | |****** | 12% | |******* | 14% | |******** | 16% | |********* | 18% | |********** | 20% | |*********** | 22% | |************ | 24% | |************* | 26% | |************** | 28% | |*************** | 30% | |**************** | 32% | |***************** | 34% | |****************** | 36% | |******************* | 38% | |******************** | 40% | |********************* | 42% | |********************** | 44% | |*********************** | 46% | |************************ | 48% | |************************* | 50% | |************************** | 52% | |*************************** | 54% | |**************************** | 56% | |***************************** | 58% | |****************************** | 60% | |******************************* | 62% | |******************************** | 64% | |********************************* | 66% | |********************************** | 68% | |*********************************** | 70% | |************************************ | 72% | |************************************* | 74% | |************************************** | 76% | |*************************************** | 78% | |**************************************** | 80% | |***************************************** | 82% | |****************************************** | 84% | |******************************************* | 86% | |******************************************** | 88% | |********************************************* | 90% | |********************************************** | 92% | |*********************************************** | 94% | |************************************************ | 96% | |************************************************* | 98% | |**************************************************| 100% summary(bayttest_analysis_thriller_comedy) ## Data ## thriller_imdb_scores, n = 33 ## comedy_imdb_scores, n = 49 ## ## Model parameters and generated quantities ## mu_x: the mean of thriller_imdb_scores ## sigma_x: the scale of thriller_imdb_scores , a consistent ## estimate of SD when nu is large. ## mu_y: the mean of comedy_imdb_scores ## sigma_y: the scale of comedy_imdb_scores ## mu_diff: the difference in means (mu_x - mu_y) ## sigma_diff: the difference in scale (sigma_x - sigma_y) ## nu: the degrees-of-freedom for the t distribution ## fitted to thriller_imdb_scores and comedy_imdb_scores ## eff_size: the effect size calculated as ## (mu_x - mu_y) / sqrt((sigma_x^2 + sigma_y^2) / 2) ## x_pred: predicted distribution for a new datapoint ## generated as thriller_imdb_scores ## y_pred: predicted distribution for a new datapoint ## generated as comedy_imdb_scores ## ## Measures ## mean sd HDIlo HDIup %&lt;comp ## mu_x 5.591 0.164 5.260 5.908 0.000 ## sigma_x 0.895 0.135 0.645 1.166 0.000 ## mu_y 5.503 0.117 5.276 5.737 0.000 ## sigma_y 0.779 0.092 0.606 0.963 0.000 ## mu_diff 0.088 0.202 -0.306 0.490 0.330 ## sigma_diff 0.116 0.156 -0.184 0.431 0.227 ## nu 33.388 28.001 2.375 89.321 0.000 ## eff_size 0.107 0.241 -0.357 0.587 0.330 ## x_pred 5.594 0.985 3.628 7.506 0.000 ## y_pred 5.497 0.850 3.855 7.231 0.000 ## %&gt;comp ## mu_x 1.000 ## sigma_x 1.000 ## mu_y 1.000 ## sigma_y 1.000 ## mu_diff 0.670 ## sigma_diff 0.773 ## nu 1.000 ## eff_size 0.670 ## x_pred 1.000 ## y_pred 1.000 ## ## &#39;HDIlo&#39; and &#39;HDIup&#39; are the limits of a 95% HDI credible interval. ## &#39;%&lt;comp&#39; and &#39;%&gt;comp&#39; are the probabilities of the respective parameter being ## smaller or larger than 0. ## ## Quantiles ## q2.5% q25% median q75% q97.5% ## mu_x 5.263 5.483 5.592 5.700 5.911 ## sigma_x 0.662 0.801 0.883 0.978 1.192 ## mu_y 5.271 5.425 5.503 5.581 5.733 ## sigma_y 0.616 0.716 0.774 0.836 0.976 ## mu_diff -0.311 -0.046 0.088 0.224 0.486 ## sigma_diff -0.174 0.011 0.109 0.214 0.443 ## nu 5.135 13.725 24.973 44.287 108.943 ## eff_size -0.365 -0.054 0.106 0.271 0.581 ## x_pred 3.640 4.975 5.600 6.216 7.525 ## y_pred 3.814 4.951 5.502 6.038 7.197 plot(bayttest_analysis_thriller_comedy) The Bayesian estimation of the difference in means (IMDB scores) between the two groups of films show no significant difference. Therefore it can be concluded, that the IMDB scores of thriller films do not significantly differ from the IMDB scores of comedy films. 2.1.3 One-Way ANOVA An experiment was conducted to ascertain, whether concentration is influenced by listening to different types of music.The participants in the experiment were assigned to four groups and asked to complete a concentration test within 15 minutes while listening to different types of music (classic, rock, opera, German hits), depending on which group they were in. Research Question: Do concentration test scores of the participants differ depending on which type of music they were listening to while completing the test? # load dataset exp_music_conc &lt;- read.table(&quot;Data/Daten_kap13.txt&quot;, sep = &quot;\\t&quot;, header = TRUE) colnames(exp_music_conc) &lt;- c(&quot;Genre&quot;, &quot;TestScore&quot;) exp_music_conc$Genre &lt;- as.factor(exp_music_conc$Genre) exp_music_conc$TestScore &lt;- as.numeric(exp_music_conc$TestScore) # inspect dataset head(exp_music_conc) ## Genre TestScore ## 1 1 16 ## 2 1 15 ## 3 1 20 ## 4 1 25 ## 5 1 28 ## 6 1 20 exp_music_conc %&gt;% count(Genre) ## Genre n ## 1 1 20 ## 2 2 20 ## 3 3 20 ## 4 4 20 describe(exp_music_conc) ## vars n mean sd median trimmed mad ## Genre* 1 80 2.50 1.13 2.5 2.50 1.48 ## TestScore 2 80 15.57 6.56 15.5 15.27 6.67 ## min max range skew kurtosis se ## Genre* 1 4 3 0.00 -1.40 0.13 ## TestScore 4 31 27 0.33 -0.67 0.73 ## violin plots - distribution of test scores exp_mc_plot &lt;- exp_music_conc %&gt;% plot_ly(x = ~Genre, y = ~TestScore, split = ~Genre, type = &quot;violin&quot;, box = list(visible = T), meanline = list(visible = T), color = ~Genre, colors = c(&quot;#f4cccc&quot;, &quot;#c0d6e4&quot;, &quot;#e68d8d&quot;, &quot;#8ab3cd&quot;)) exp_mc_plot &lt;- exp_mc_plot %&gt;% layout(title = &quot;Distribution of Test Scores&quot;, xaxis = list(title = &quot;Genre&quot;), yaxis = list(title = &quot;Test Score&quot;, zeroline = F), showlegend = FALSE, margin = list(l = 75, r = 75, b = 75, t = 75)) exp_mc_plot # install and load packages needed for main # analysis install.packages(&#39;AICcmodavg&#39;) # install.packages(&#39;BayesFactor&#39;) # install.packages(&#39;rstanarm&#39;) # install.packages(&#39;rstan&#39;) # remotes::install_github(&#39;bayesstuff/stanova&#39;) # install.packages(&#39;emmeans&#39;) # install.packages(&#39;coda&#39;) # install.packages(&#39;logspline&#39;) # install.packages(&#39;bayestestR&#39;) # library(emmeans) library(stanova) # library(rstanarm) library(rstan) library(coda) # library(logspline) library(bayestestR) # conduct Bayesian One-Way ANOVA anovaBF(TestScore ~ Genre, data = exp_music_conc, whichModels = &quot;all&quot;, progress = FALSE) ## Bayes factor analysis ## -------------- ## [1] Genre : 548525798277 ±0% ## ## Against denominator: ## Intercept only ## --- ## Bayes factor type: BFlinearModel, JZS # conduct a post-hoc test on / draw contrasts # from the posterior distribution exp_stan_glm &lt;- stan_glm(TestScore ~ Genre, data = exp_music_conc, iter = 2000, warmup = 500, chains = 3, thin = 2, refresh = 0, prior = normal(0, 100), prior_aux = cauchy(0, 5)) summary(exp_stan_glm) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: TestScore ~ Genre ## algorithm: sampling ## sample: 2250 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 80 ## predictors: 4 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 23.2 1.0 22.0 23.3 24.5 ## Genre2 -7.7 1.4 -9.5 -7.7 -6.0 ## Genre3 -9.0 1.4 -10.8 -9.0 -7.2 ## Genre4 -13.9 1.4 -15.7 -13.9 -12.2 ## sigma 4.3 0.4 3.9 4.3 4.8 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 15.6 0.7 14.7 15.6 16.5 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 1729 ## Genre2 0.0 1.0 1888 ## Genre3 0.0 1.0 1960 ## Genre4 0.0 1.0 1894 ## sigma 0.0 1.0 2315 ## mean_PPD 0.0 1.0 2312 ## log-posterior 0.0 1.0 1589 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). tidyMCMC(exp_stan_glm, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;) ## # A tibble: 5 × 5 ## term estimate std.error conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Interce… 23.3 0.981 21.3 25.1 ## 2 Genre2 -7.72 1.37 -10.4 -5.10 ## 3 Genre3 -9.04 1.38 -11.8 -6.36 ## 4 Genre4 -13.9 1.39 -16.6 -11.1 ## 5 sigma 4.32 0.362 3.64 5.01 According to the results of the above calculations none of the credible intervals for the comparisons of the factors one trough four (Genre one through four) include zero. We can therefore conclude, that the concentration test scores of the participants do indeed differ depending on which type of music they were listening to while completing the test. 2.1.4 Regression An experiment was conducted in which the context people interact with each other was manipulated: The participants had to either speak to (1) a friend or (2) a professor. During the experiment the number of gestures the participants made while interacting where counted. This example is based on a paper by (Winter &amp; Bürkner, 2021). Research Question: Does the social context (interacting with a friend or a professor) and the languages spoken by the participants modulate the non-verbal politeness strategies (i.e. number of gestures) of the participants. # load and wrangle data load dataset dyads &lt;- read.csv(&quot;Data/dyads.csv&quot;) colnames(dyads) &lt;- c(&quot;ID&quot;, &quot;SocialContext&quot;, &quot;Duration&quot;, &quot;Language&quot;, &quot;BinaryGender&quot;, &quot;NumberGestures&quot;) dyads$SocialContext &lt;- as.factor(dyads$SocialContext) dyads$SocialContext &lt;- recode_factor(dyads$SocialContext, friend = &quot;Friend&quot;, prof = &quot;Professor&quot;) dyads$Duration &lt;- as.numeric(dyads$Duration) dyads$Language &lt;- as.factor(dyads$Language) dyads$BinaryGender &lt;- as.factor(dyads$BinaryGender) dyads$NumberGestures &lt;- as.integer(dyads$NumberGestures) dyads$GestureRate &lt;- rep(NA, length(dyads$ID)) for (i in 1:length(dyads$ID)) { dyads$GestureRate[i] &lt;- dyads$NumberGestures[i]/dyads$Duration[i] } # inspect dataset head(dyads) ## ID SocialContext Duration Language BinaryGender ## 1 Catalan_1 Friend 137 Catalan M ## 2 Catalan_1 Professor 136 Catalan M ## 3 Catalan_2 Friend 90 Catalan F ## 4 Catalan_2 Professor 107 Catalan F ## 5 Catalan_3 Friend 181 Catalan M ## 6 Catalan_3 Professor 165 Catalan M ## NumberGestures GestureRate ## 1 61 0.4452555 ## 2 78 0.5735294 ## 3 31 0.3444444 ## 4 40 0.3738318 ## 5 81 0.4475138 ## 6 49 0.2969697 describe(dyads) ## vars n mean sd median trimmed mad ## ID* 1 54 14.00 7.86 14.0 14.00 10.38 ## SocialContext* 2 54 1.50 0.50 1.5 1.50 0.74 ## Duration 3 54 128.43 32.84 133.5 129.32 28.91 ## Language* 4 54 1.48 0.50 1.0 1.48 0.00 ## BinaryGender* 5 54 1.48 0.50 1.0 1.48 0.00 ## NumberGestures 6 54 49.44 22.69 49.0 49.00 25.20 ## GestureRate 7 54 0.38 0.13 0.4 0.39 0.12 ## min max range skew kurtosis se ## ID* 1.00 27.0 26.0 0.00 -1.27 1.07 ## SocialContext* 1.00 2.0 1.0 0.00 -2.04 0.07 ## Duration 58.00 187.0 129.0 -0.31 -0.80 4.47 ## Language* 1.00 2.0 1.0 0.07 -2.03 0.07 ## BinaryGender* 1.00 2.0 1.0 0.07 -2.03 0.07 ## NumberGestures 10.00 101.0 91.0 0.20 -0.81 3.09 ## GestureRate 0.09 0.6 0.5 -0.37 -0.75 0.02 ## 2 measures per ID dyads %&gt;% count(ID) ## ID n ## 1 Catalan_1 2 ## 2 Catalan_11 2 ## 3 Catalan_12 2 ## 4 Catalan_13 2 ## 5 Catalan_14 2 ## 6 Catalan_16 2 ## 7 Catalan_2 2 ## 8 Catalan_3 2 ## 9 Catalan_4 2 ## 10 Catalan_5 2 ## 11 Catalan_6 2 ## 12 Catalan_7 2 ## 13 Catalan_8 2 ## 14 Catalan_9 2 ## 15 Korean_1 2 ## 16 Korean_10 2 ## 17 Korean_11 2 ## 18 Korean_12 2 ## 19 Korean_13 2 ## 20 Korean_2 2 ## 21 Korean_3 2 ## 22 Korean_4 2 ## 23 Korean_5 2 ## 24 Korean_6 2 ## 25 Korean_7 2 ## 26 Korean_8 2 ## 27 Korean_9 2 ## number of participants dyads %&gt;% count(ID) %&gt;% nrow() ## [1] 27 ## mean number of gestures dyads %&gt;% group_by(SocialContext) %&gt;% summarize(`Mean Number of Gestures` = mean(NumberGestures)) ## # A tibble: 2 × 2 ## SocialContext `Mean Number of Gestures` ## &lt;fct&gt; &lt;dbl&gt; ## 1 Friend 53.8 ## 2 Professor 45.1 ## mean rate of gestures (number of gestures divided by ## duration) dyads %&gt;% group_by(SocialContext) %&gt;% summarize(`Mean Rate of Gestures` = mean(GestureRate)) ## # A tibble: 2 × 2 ## SocialContext `Mean Rate of Gestures` ## &lt;fct&gt; &lt;dbl&gt; ## 1 Friend 0.398 ## 2 Professor 0.361 ## violin plots - number of gestures exp_dyads_plot &lt;- dyads %&gt;% plot_ly(type = &quot;violin&quot;) exp_dyads_plot &lt;- exp_dyads_plot %&gt;% add_trace(x = ~SocialContext[dyads$Language == &quot;Catalan&quot;], y = ~NumberGestures[dyads$Language == &quot;Catalan&quot;], legendgroup = &quot;Catalan&quot;, scalegroup = &quot;Catalan&quot;, name = &quot;Catalan&quot;, box = list(visible = T), meanline = list(visible = T), color = I(&quot;#f4cccc&quot;)) exp_dyads_plot &lt;- exp_dyads_plot %&gt;% add_trace(x = ~SocialContext[dyads$Language == &quot;Korean&quot;], y = ~NumberGestures[dyads$Language == &quot;Korean&quot;], legendgroup = &quot;Korean&quot;, scalegroup = &quot;Korean&quot;, name = &quot;Korean&quot;, box = list(visible = T), meanline = list(visible = T), color = I(&quot;#c0d6e4&quot;)) exp_dyads_plot &lt;- exp_dyads_plot %&gt;% layout(title = &quot;Distribution of Number of Gestures&quot;, xaxis = list(title = &quot;Social Context&quot;), yaxis = list(title = &quot;Gesture Rate&quot;, zeroline = F), legend = list(title = list(text = &quot;&lt;b&gt; Language &lt;/b&gt;&quot;)), violinmode = &quot;group&quot;, margin = list(l = 75, r = 75, b = 75, t = 75)) exp_dyads_plot # install and load packages needed for main analysis # install.packages(&#39;StanHeaders&#39;) # install.packages(&#39;brms&#39;) install.packages(&#39;bayesplot&#39;) # library(StanHeaders) library(brms) library(bayesplot) # conduct main analysis Model 1: NumberGestures ~ 1 + # SocialContext gr.sc.brm &lt;- brm(NumberGestures ~ 1 + SocialContext, data = dyads, family = poisson(), seed = 666) ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 2.7e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.030532 seconds (Warm-up) ## Chain 1: 0.026898 seconds (Sampling) ## Chain 1: 0.05743 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 8e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.02351 seconds (Warm-up) ## Chain 2: 0.02258 seconds (Sampling) ## Chain 2: 0.04609 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 7e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.023752 seconds (Warm-up) ## Chain 3: 0.023967 seconds (Sampling) ## Chain 3: 0.047719 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 9e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.023397 seconds (Warm-up) ## Chain 4: 0.024771 seconds (Sampling) ## Chain 4: 0.048168 seconds (Total) ## Chain 4: ### plots regarding MCMC draws trace plots of MCMC draws mcmc_trace(gr.sc.brm) #### kernel density plots of posterior draws mcmc_dens_overlay(gr.sc.brm) #### grid of autocorrelation plots mcmc_acf(gr.sc.brm) ### summary of all priors prior_summary(gr.sc.brm) ## prior class coef ## (flat) b ## (flat) b SocialContextProfessor ## student_t(3, 3.9, 2.5) Intercept ## group resp dpar nlpar lb ub source ## default ## (vectorized) ## default ### summary of model parameters summary(gr.sc.brm) ## Family: poisson ## Links: mu = log ## Formula: NumberGestures ~ 1 + SocialContext ## Data: dyads (Number of observations: 54) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI ## Intercept 3.99 0.03 3.93 ## SocialContextProfessor -0.18 0.04 -0.26 ## u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.04 1.00 3182 2766 ## SocialContextProfessor -0.10 1.00 2931 2267 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ### plotting from posterior distribution poi_ef_grsc &lt;- conditional_effects(gr.sc.brm)[[1]] poi_ef_grsc &lt;- rename(poi_ef_grsc, Estimate = &quot;estimate__&quot;, lower = &quot;lower__&quot;, upper = &quot;upper__&quot;, se = &quot;se__&quot;) effects_grsc.plot &lt;- poi_ef_grsc %&gt;% ggplot(aes(x = SocialContext, y = Estimate, ymin = lower, ymax = upper)) + geom_errorbar(width = 0.25, size = 0.6, color = &quot;#f4cccc&quot;) + geom_point(size = 3, shape = 16, color = &quot;#f4cccc&quot;) effects_grsc.plotly &lt;- ggplotly(effects_grsc.plot) %&gt;% layout(title = &quot;Conditional Effects - Model 1&quot;, plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Social Context&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(title = &quot;Estimate&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), margin = list(l = 75, r = 75, b = 75, t = 75)) effects_grsc.plotly ## Model 2: NumberGestures ~ 1 + SocialContext + ## Language gr.sc.l.brm &lt;- update(gr.sc.brm, formula. = ~. + Language, newdata = dyads, seed = 666) ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 1.5e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.032638 seconds (Warm-up) ## Chain 1: 0.030128 seconds (Sampling) ## Chain 1: 0.062766 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 1e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.027986 seconds (Warm-up) ## Chain 2: 0.028885 seconds (Sampling) ## Chain 2: 0.056871 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 1e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.028595 seconds (Warm-up) ## Chain 3: 0.02911 seconds (Sampling) ## Chain 3: 0.057705 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 9e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.027175 seconds (Warm-up) ## Chain 4: 0.025514 seconds (Sampling) ## Chain 4: 0.052689 seconds (Total) ## Chain 4: ### plots regarding MCMC draws trace plots of MCMC draws mcmc_trace(gr.sc.l.brm) #### kernel density plots of posterior draws mcmc_dens_overlay(gr.sc.l.brm) #### grid of autocorrelation plots mcmc_acf(gr.sc.l.brm) ### summary of all priors prior_summary(gr.sc.l.brm) ## prior class coef ## (flat) b ## (flat) b LanguageKorean ## (flat) b SocialContextProfessor ## student_t(3, 3.9, 2.5) Intercept ## group resp dpar nlpar lb ub source ## default ## (vectorized) ## (vectorized) ## default ### summary of model parameters summary(gr.sc.l.brm) ## Family: poisson ## Links: mu = log ## Formula: NumberGestures ~ SocialContext + Language ## Data: dyads (Number of observations: 54) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI ## Intercept 4.06 0.03 4.00 ## SocialContextProfessor -0.18 0.04 -0.25 ## LanguageKorean -0.17 0.04 -0.24 ## u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.12 1.00 4428 3044 ## SocialContextProfessor -0.10 1.00 3715 3083 ## LanguageKorean -0.10 1.00 4003 3074 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ### plotting from posterior distribution poi_ef_grscl &lt;- conditional_effects(gr.sc.l.brm)[[2]] poi_ef_grscl &lt;- rename(poi_ef_grscl, Estimate = &quot;estimate__&quot;, lower = &quot;lower__&quot;, upper = &quot;upper__&quot;, se = &quot;se__&quot;) effects_grscl.plot &lt;- poi_ef_grscl %&gt;% ggplot(aes(x = Language, y = Estimate, ymin = lower, ymax = upper)) + geom_errorbar(width = 0.25, size = 0.6, color = &quot;#c0d6e4&quot;) + geom_point(size = 3, shape = 16, color = &quot;#c0d6e4&quot;) effects_grscl.plotly &lt;- ggplotly(effects_grscl.plot) %&gt;% layout(title = &quot;Conditional Effects - Model 2&quot;, plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Language&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(title = &quot;Estimate&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), margin = list(l = 75, r = 75, b = 75, t = 75)) effects_grscl.plotly ## Model 3: NumberGestures ~ 1 + SocialContext + ## Language + SocialContext*Language gr.sc.l.inter.brm &lt;- update(gr.sc.l.brm, formula. = ~. + Language * SocialContext, newdata = dyads, seed = 666) ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 1.5e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.040769 seconds (Warm-up) ## Chain 1: 0.040677 seconds (Sampling) ## Chain 1: 0.081446 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 9e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.039829 seconds (Warm-up) ## Chain 2: 0.042751 seconds (Sampling) ## Chain 2: 0.08258 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 8e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.040082 seconds (Warm-up) ## Chain 3: 0.036976 seconds (Sampling) ## Chain 3: 0.077058 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;bd10aecfb8109c66a47af15ebb31773a&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 8e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.03734 seconds (Warm-up) ## Chain 4: 0.038842 seconds (Sampling) ## Chain 4: 0.076182 seconds (Total) ## Chain 4: ### plots regarding MCMC draws trace plots of MCMC draws mcmc_trace(gr.sc.l.inter.brm) #### kernel density plots of posterior draws mcmc_dens_overlay(gr.sc.l.inter.brm) #### grid of autocorrelation plots mcmc_acf(gr.sc.l.inter.brm) ### summary of all priors prior_summary(gr.sc.l.inter.brm) ## prior class ## (flat) b ## (flat) b ## (flat) b ## (flat) b ## student_t(3, 3.9, 2.5) Intercept ## coef group resp dpar ## ## LanguageKorean ## SocialContextProfessor ## SocialContextProfessor:LanguageKorean ## ## nlpar lb ub source ## default ## (vectorized) ## (vectorized) ## (vectorized) ## default ### summary of model parameters summary(gr.sc.l.inter.brm) ## Family: poisson ## Links: mu = log ## Formula: NumberGestures ~ SocialContext + Language + SocialContext:Language ## Data: dyads (Number of observations: 54) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Population-Level Effects: ## Estimate Est.Error ## Intercept 4.00 0.04 ## SocialContextProfessor -0.04 0.05 ## LanguageKorean -0.03 0.05 ## SocialContextProfessor:LanguageKorean -0.32 0.08 ## l-95% CI u-95% CI ## Intercept 3.93 4.07 ## SocialContextProfessor -0.15 0.06 ## LanguageKorean -0.13 0.07 ## SocialContextProfessor:LanguageKorean -0.47 -0.16 ## Rhat Bulk_ESS ## Intercept 1.00 2179 ## SocialContextProfessor 1.00 1980 ## LanguageKorean 1.00 2147 ## SocialContextProfessor:LanguageKorean 1.00 1987 ## Tail_ESS ## Intercept 2775 ## SocialContextProfessor 2008 ## LanguageKorean 2619 ## SocialContextProfessor:LanguageKorean 2220 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ### plotting from posterior distribution poi_ef_grscl_inter &lt;- conditional_effects(gr.sc.l.inter.brm)[[3]] poi_ef_grscl_inter &lt;- rename(poi_ef_grscl_inter, Estimate = &quot;estimate__&quot;, lower = &quot;lower__&quot;, upper = &quot;upper__&quot;, se = &quot;se__&quot;) effects_grscl_inter.plot &lt;- poi_ef_grscl_inter %&gt;% ggplot(aes(x = SocialContext, y = Estimate, ymin = lower, ymax = upper, color = Language)) + geom_errorbar(width = 0.25, size = 0.6, position = position_dodge(0.3)) + geom_point(size = 3, shape = 16, position = position_dodge(0.3)) + scale_color_manual(values = c(&quot;#8ab3cd&quot;, &quot;#e68d8d&quot;)) effects_grscl_inter.plotly &lt;- ggplotly(effects_grscl_inter.plot) %&gt;% layout(title = &quot;Conditional Effects - Model 3&quot;, plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Language&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(title = &quot;Estimate&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), margin = list(l = 75, r = 75, b = 75, t = 75)) effects_grscl_inter.plotly ## compare models gr.sc.brm_loo &lt;- loo(gr.sc.brm) gr.sc.l.brm_loo &lt;- loo(gr.sc.l.brm) gr.sc.l.inter.brm_loo &lt;- loo(gr.sc.l.inter.brm) loos &lt;- loo_compare(gr.sc.brm_loo, gr.sc.l.brm_loo, gr.sc.l.inter.brm_loo) loos ## elpd_diff se_diff ## gr.sc.l.inter.brm 0.0 0.0 ## gr.sc.l.brm -2.1 13.6 ## gr.sc.brm -6.6 19.9 In order to evaluate the three models based on how well they predict unseen data, the models were compared using (approximate) leave-one-out cross-validation (LOO-CV). The model in the first row of the table above is taken as the baseline. It is the model with the highest ELPD value (Expected Log-Predictive Density - measure of expected predictive accuracy) in the comparison set. Based on the fact though that the standard errors for the differences in the ELPD values are much higher than the respective differences in the ELPD values themselves, one cannot assume, that either the second model or the third model perform better than the first model. According to the results of the above calculations one can therefore conclude, that the social context (interacting with a friend or a professor) did indeed modulate the non-verbal politeness strategies (i.e. number of gestures) of the participants. 2.2 Markov Chain Monte Carlo Methods Markov Chain Monte Carlo (MCMC) methods are aimed at generating samples from a difficult probability distribution, that can be defined up to a factor. In Bayesian statistics it is used to generate posterior distributions. They are several different commonly used MCMC algorithms. One MCMC algorithm, that is often used in the context of Bayesian statistics is the Metropolis-Hastings Algorithm. 2.2.1 Understanding the Basics For a brief explanation of the concepts of Markov Chains, Monte Carlo Simulations and MCMC methods I recommend watching the following videos: Markov Chains (ritvikmath, 2020) Video: “Markov Chains : Data Science Basics” Monte Carlo Simulations (ritvikmath, 2021a) Video: “Monte Carlo Methods : Data Science Basics” Markov Chain Monte Carlo Methods (ritvikmath, 2021b) Video: “Markov Chain Monte Carlo (MCMC) : Data Science Concepts” 2.2.2 Real World Application There are several different packages in R and in Python, which one can use to perform calculations using MCMC methods. The examples below though do not use any of these packages. Thanks to the work of some of my fellow students I am able to present the inner workings of the actual functions needed to perform analyses using the MCMC approach. The specific MCMC algorithm used in the examples below is the Metropolis-Hastings Algorithm. Please note, that the following examples are coded using R as well as Python. The examples below are all based on actual data retrieved from the website of the Open-Source Psychometrics Project. The dataset, that was used, contains the answers of N = 18,192 participants to the Short Dark Triad (SD3) questionnaire (Jones &amp; Paulhus, 2014). Said questionnaire contains 27 items to assess the extent of the elements of the so-called “Dark Triad” which are narcissism, psychopathy, and machiavellianism. Answers are scored on a 5-point Likert scale (1 = disagree strongly; 5 = agree strongly). 2.2.2.1 Load and Inspect the Data # read in data set (Short Dark Triad) sdt = pd.read_csv(&quot;Data/short_dark_triad.csv&quot;, delimiter=&quot;\\t&quot;) # reverse items N2, N6, N8, P2, P7 sdt[&#39;N2R&#39;] = (sdt[&#39;N2&#39;] - 6).abs() sdt[&#39;N6R&#39;] = (sdt[&#39;N6&#39;] - 6).abs() sdt[&#39;N8R&#39;] = (sdt[&#39;N8&#39;] - 6).abs() sdt[&#39;P2R&#39;] = (sdt[&#39;P2&#39;] - 6).abs() sdt[&#39;P7R&#39;] = (sdt[&#39;P7&#39;] - 6).abs() # get averages for machiavellianism., narcissism, and psychopathy sdt[&#39;M_avg&#39;] = sdt[[&#39;M1&#39;, &#39;M2&#39;, &#39;M3&#39;, &#39;M4&#39;, &#39;M5&#39;, &#39;M6&#39;, &#39;M7&#39;, &#39;M8&#39;, &#39;M9&#39;]].mean(axis=1).round(2) sdt[&#39;N_avg&#39;] = sdt[[&#39;N1&#39;, &#39;N2R&#39;, &#39;N3&#39;, &#39;N4&#39;, &#39;N5&#39;, &#39;N6R&#39;, &#39;N7&#39;, &#39;N8R&#39;, &#39;N9&#39;]].mean(axis=1).round(2) sdt[&#39;P_avg&#39;] = sdt[[&#39;P1&#39;, &#39;P2R&#39;, &#39;P3&#39;, &#39;P4&#39;, &#39;P5&#39;, &#39;P6&#39;, &#39;P7R&#39;, &#39;P8&#39;, &#39;P9&#39;]].mean(axis=1).round(2) sdt[&#39;DT_avg&#39;] = sdt[[&#39;M_avg&#39;, &#39;N_avg&#39;, &#39;P_avg&#39;]].mean(axis=1).round(2) # only include the first 1000 rows sdt = sdt.iloc[:1000,:] # load data &amp; preprocessing read in data set (Short Dark # Triad) sdt_r &lt;- read.csv(&quot;Data/short_dark_triad.csv&quot;, sep = &quot;\\t&quot;) ## reverse items N2, N6, N8, P2, P7 sdt_r$N2R &lt;- abs(sdt_r$N2 - 6) sdt_r$N6R &lt;- abs(sdt_r$N6 - 6) sdt_r$N8R &lt;- abs(sdt_r$N8 - 6) sdt_r$P2R &lt;- abs(sdt_r$P2 - 6) sdt_r$P7R &lt;- abs(sdt_r$P7 - 6) ## get averages for machiavellianism., narcissism, and ## psychopathy sdt_r$M_avg &lt;- round(rowMeans(sdt_r[, c(&quot;M1&quot;, &quot;M2&quot;, &quot;M3&quot;, &quot;M4&quot;, &quot;M5&quot;, &quot;M6&quot;, &quot;M7&quot;, &quot;M8&quot;, &quot;M9&quot;)], na.rm = TRUE), 2) sdt_r$N_avg &lt;- round(rowMeans(sdt_r[, c(&quot;N1&quot;, &quot;N2R&quot;, &quot;N3&quot;, &quot;N4&quot;, &quot;N5&quot;, &quot;N6R&quot;, &quot;N7&quot;, &quot;N8R&quot;, &quot;N9&quot;)], na.rm = TRUE), 2) sdt_r$P_avg &lt;- round(rowMeans(sdt_r[, c(&quot;P1&quot;, &quot;P2R&quot;, &quot;P3&quot;, &quot;P4&quot;, &quot;P5&quot;, &quot;P6&quot;, &quot;P7R&quot;, &quot;P8&quot;, &quot;P9&quot;)], na.rm = TRUE), 2) sdt_r$DT_avg &lt;- round(rowMeans(sdt_r[, c(&quot;M_avg&quot;, &quot;N_avg&quot;, &quot;P_avg&quot;)], na.rm = TRUE), 2) ## only include the first 1000 rows sdt_r &lt;- sdt_r[1:1000, ] # inspect data distplot.M_avg &lt;- ggplot(sdt_r, aes(x = M_avg, color = &quot;Density&quot;)) + geom_histogram(aes(y = after_stat(density)), bins = 31, fill = &quot;#f4cccc&quot;, alpha = 0.5) + geom_density(color = &quot;#e68d8d&quot;) + geom_rug(color = &quot;#f4cccc&quot;) + ylab(&quot;&quot;) + xlab(&quot;&quot;) + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(Density = &quot;#f4cccc&quot;)) distplot.M_avg.plotly &lt;- ggplotly(distplot.M_avg) %&gt;% layout(plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Machiavellianism\\n[mean score]&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(title = &quot;Density&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;)) ################ distplot.N_avg &lt;- ggplot(sdt_r, aes(x = N_avg, color = &quot;Density&quot;)) + geom_histogram(aes(y = after_stat(density)), bins = 31, fill = &quot;#f4cccc&quot;, alpha = 0.5) + geom_density(color = &quot;#e68d8d&quot;) + geom_rug(color = &quot;#f4cccc&quot;) + ylab(&quot;&quot;) + xlab(&quot;&quot;) + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(Density = &quot;#f4cccc&quot;)) distplot.N_avg.plotly &lt;- ggplotly(distplot.N_avg) %&gt;% layout(plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Narcissism\\n[mean score]&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;)) ################ distplot.P_avg &lt;- ggplot(sdt_r, aes(x = P_avg, color = &quot;Density&quot;)) + geom_histogram(aes(y = after_stat(density)), bins = 31, fill = &quot;#f4cccc&quot;, alpha = 0.5) + geom_density(color = &quot;#e68d8d&quot;) + geom_rug(color = &quot;#f4cccc&quot;) + ylab(&quot;&quot;) + xlab(&quot;&quot;) + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(Density = &quot;#f4cccc&quot;)) distplot.P_avg.plotly &lt;- ggplotly(distplot.P_avg) %&gt;% layout(plot_bgcolor = &quot;#ffffff&quot;, xaxis = list(title = &quot;Psychopathy\\n[mean score]&quot;, zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;), yaxis = list(zerolinecolor = &quot;#eeeeee&quot;, zerolinewidth = 2, gridcolor = &quot;#eeeeee&quot;)) distplots.sdt &lt;- subplot(distplot.M_avg.plotly, distplot.N_avg.plotly, distplot.P_avg.plotly, nrows = 1, margin = 0.03, titleY = TRUE, titleX = TRUE) %&gt;% layout(title = &quot;Distribution Plots - SDT&quot;, margin = list(l = 75, r = 75, b = 75, t = 75)) distplots.sdt 2.2.2.2 Example #1 Research Question: Which of the three constructs of the “Dark Triad” has the highest expected average value? 2.2.2.2.1 Defining the MCMC Simulation The following functions enable us to perform the actual analysis using the MCMC approach. # import packages needed for main analysis # import pandas as pd # import numpy as np # import scipy.stats as st # from statsmodels.graphics.tsaplots import plot_acf # import matplotlib.pyplot as plt # import seaborn as sns # from collections import Counter # install.packages(&quot;reticulate&quot;) # library(reticulate) # define MCMC simulation to estimate value x ## code function to define target distribution def target_fun(X, theta): # 1. target function ln f(theta) = ln p(x|theta)p(x) # likelihood defined as ~N(theta,1) loglik = np.sum(np.log(st.norm(loc=theta, scale=1).pdf(X))) # prior defined as ~N(0,1) logprior = np.log(st.norm(loc=0, scale=1).pdf(theta)) return loglik + logprior # as log we return sum ## code function to define proposal distribution def proposal_fun(theta_curr): # 2. proposal function q(theta) based on Gaussian normal distribution # ~N(theta_curr,0.2) theta_new = st.norm(loc=theta_curr, scale=0.2).rvs() return theta_new def proposal_func_prob(x1, x2): # for calculation of weighing matrix: q(theta_1|theta_2) q = st.norm(loc=x1, scale=0.2).pdf(x2) return q ## code function to estimate posterior distribution def mcmc_mh_posterior(X, theta_init, target_fun, proposal_fun, proposal_func_prob, n_iter=1000): # Metropolis-Hastings to estimate posterior thetas = [] # 3. create container thetas theta_curr = theta_init # 4. initialize theta_0 accept_rates = [] accept_cum = 0 # 5. loop over number of iterations of Markov chain for i in range(1, n_iter+1): theta_new = proposal_fun(theta_curr) # 6. Calculate target function f(theta_curr) prob_curr = target_fun(X, theta_curr) # Calculate target function f(theta_theta_new) # -&gt; values will be used for acceptance ratio prob_new = target_fun(X, theta_new) # 7. calculate acceptance ratio r # we calculate the prob=exp(x) only when prob&lt;1 # so the exp(x) will not overflow for large x if prob_new &gt; prob_curr: acceptance_ratio = 1 else: # weigthing ratio q(theta_curr|theta_new)/q(theta_new|theta_curr) qr = proposal_func_prob(theta_curr,theta_new)/proposal_func_prob(theta_curr, theta_new) acceptance_ratio = np.exp(prob_new - prob_curr)*qr # 8. set acceptance probability A acceptance_prob = min(1, acceptance_ratio) #9. compare A with random z drawn from uniform distribution if acceptance_prob &gt; st.uniform(0,1).rvs(): # if A&gt;z: update theta_curr, add theta to drawn sample theta_curr = theta_new accept_cum = accept_cum+1 thetas.append(theta_new) else: # if A&lt;=z: do not update theta_curr, # add theta_curr again to drawn sample thetas.append(theta_curr) accept_rates.append(accept_cum/i) return thetas, accept_rates 2.2.2.2.2 Additional Functions The functions below enable us to visually inspect the MCMC simulation as well as visualize and report its results. ## code function to plot results of MCMC simulation in r ## using plotly before using this function convert ## python objects to r objects convert python list to ## numeric r vetor: r_thetas_M_avg &lt;- ## unlist(py$thetas_M_avg) convert python integer to ## numeric r vetor: r_burn_in_RQ1 &lt;- py$burn_in_RQ1 rplotly_mcmcres &lt;- function(data, burn_in, colourplt = c(&quot;#c0d6e4&quot;, &quot;#8ab3cd&quot;, &quot;#f4cccc&quot;, &quot;#e68d8d&quot;), theta_name, acf_lags_max = 100) { # plot full trace with plotly trace_full &lt;- plot_ly(y = data, type = &quot;scatter&quot;, mode = &quot;lines&quot;, line = list(color = colourplt[2]), hovertemplate = paste(&quot;&lt;b&gt;Iteration&lt;/b&gt;: %{x}&quot;, &quot;&lt;br&gt;&lt;b&gt;Theta Value&lt;/b&gt;: %{y}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;)) %&gt;% layout(title = paste0(&quot;Full Trace - incl. burn-in (&quot;, burn_in, &quot;)&quot;), xaxis = list(title = &quot;Number of Iterations&quot;, zeroline = FALSE), yaxis = list(title = paste0(&quot;&lt;i&gt;theta&lt;/i&gt; - &quot;, theta_name)), margin = list(l = 75, r = 75, b = 75, t = 75)) # plot trace excl. burn-in with plotly data_burned &lt;- data[-c(1:burn_in)] trace_burned &lt;- plot_ly(y = data_burned, type = &quot;scatter&quot;, mode = &quot;lines&quot;, line = list(color = colourplt[4]), hovertemplate = paste(&quot;&lt;b&gt;Iteration&lt;/b&gt;: %{x}&quot;, &quot;&lt;br&gt;&lt;b&gt;Theta Value&lt;/b&gt;: %{y}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;)) %&gt;% layout(title = paste0(&quot;Trace - after discarding burn-in (&quot;, burn_in, &quot;)&quot;), xaxis = list(title = &quot;Number of Iterations&quot;, zeroline = FALSE), yaxis = list(title = paste0(&quot;&lt;i&gt;theta&lt;/i&gt; - &quot;, theta_name)), margin = list(l = 75, r = 75, b = 75, t = 75)) # distribution plot of theta - after burn-in data_burned_density &lt;- density(data_burned) histplot.theta &lt;- plot_ly() %&gt;% add_histogram(x = data_burned, marker = list(color = colourplt[3], line = list(color = colourplt[4], width = 2)), hovertemplate = paste(&quot;&lt;b&gt;Count&lt;/b&gt;: %{y}&quot;, &quot;&lt;br&gt;&lt;b&gt;Theta Value&lt;/b&gt;: %{x}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;), name = &quot;Histogram&quot;) %&gt;% add_lines(x = data_burned_density$x, y = data_burned_density$y, fill = &quot;none&quot;, yaxis = &quot;y2&quot;, name = &quot;Density&quot;, line = list(color = colourplt[2]), hovertemplate = paste(&quot;&lt;b&gt;Density&lt;/b&gt;: %{y}&quot;, &quot;&lt;br&gt;&lt;b&gt;Theta Value&lt;/b&gt;: %{x}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;)) %&gt;% layout(title = paste0(&quot;Distribution of theta after discarding burn-in (&quot;, burn_in, &quot;)&quot;), yaxis = list(title = &quot;Count&quot;, zeroline = FALSE, gridcolor = colourplt[3]), yaxis2 = list(title = &quot;Density&quot;, overlaying = &quot;y&quot;, side = &quot;right&quot;, zeroline = FALSE, gridcolor = colourplt[1]), xaxis = list(title = paste0(&quot;&lt;i&gt;theta&lt;/i&gt; - &quot;, theta_name), zeroline = FALSE), margin = list(l = 75, r = 75, b = 75, t = 75)) # autocorrelation plot - after burn-in acf_res &lt;- acf(x = data_burned, lag.max = acf_lags_max, type = &quot;correlation&quot;, plot = FALSE) acf_plot_data &lt;- data.frame(lag = acf_res$lag[, , 1], acf = acf_res$acf[, , 1]) acf_plot_mcmc &lt;- plot_ly(acf_plot_data, x = ~lag, y = ~acf, type = &quot;scatter&quot;, mode = &quot;lines+markers&quot;, line = list(color = colourplt[3]), marker = list(color = colourplt[4]), hovertemplate = paste(&quot;&lt;b&gt;Lag&lt;/b&gt;: %{x}&quot;, &quot;&lt;br&gt;&lt;b&gt;Autocorrelation&lt;/b&gt;: %{y}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;)) %&gt;% layout(title = paste0(&quot;Autocorrelation Plot after discarding burn-in (&quot;, burn_in, &quot;)&quot;), xaxis = list(title = &quot;Lag&quot;, zeroline = FALSE), yaxis = list(title = &quot;Autocorrelation&quot;, range = c(-1.1, 1.1), zerolinewidth = 0.5), margin = list(l = 75, r = 75, b = 75, t = 75)) # save plots to a list mcmc_plots &lt;- list(trace_full, trace_burned, histplot.theta, acf_plot_mcmc) names(mcmc_plots) &lt;- c(&quot;Full Trace&quot;, &quot;Trace after Burn-In&quot;, &quot;Distribution of Theta&quot;, &quot;Autocorrelation Plot&quot;) # return list of plots return(mcmc_plots) } ## code function to calculate highest probability density region def hpd(trace, mass_frac) : &quot;&quot;&quot; Returns highest probability density region given by a set of samples. Parameters ---------- trace : array 1D array of MCMC samples for a single variable mass_frac : float with 0 &lt; mass_frac &lt;= 1 The fraction of the probability to be included in the HPD. For example, `massfrac` = 0.95 gives a 95% HPD. Returns ------- output : array, shape (2,) The bounds of the HPD &quot;&quot;&quot; # Get sorted list d = np.sort(np.copy(trace)) # Number of total samples taken n = len(trace) # Get number of samples that should be included in HPD n_samples = np.floor(mass_frac * n).astype(int) # Get width (in units of data) of all intervals with n_samples samples int_width = d[n_samples:] - d[:n-n_samples] # Pick out minimal interval min_int = np.argmin(int_width) # Return interval return np.array([d[min_int], d[min_int+n_samples]]) ## code function to return further results of mcmc analysis def mcmc_overview(thetas, burn_in): mode_list = [ &#39;%.4f&#39; % elem for elem in thetas ] mode_raw = Counter(mode_list[burn_in:]) res = f&quot;&quot;&quot; {&#39;-&#39;*50} RESULTS OF MCMC ANALYIS {&#39;-&#39;*50} Burn-In Period: first {burn_in} Mode of the Distribution: {mode_raw.most_common(1)[0][0]} Mean of the Distribution: {np.mean(thetas[burn_in:]): .4f} SD of the Distribution: {np.std(thetas[burn_in:]): .4f} Highest Density Interval (95%): {hpd(thetas[burn_in:], 0.95).round(4)} {&#39;-&#39;*50} &quot;&quot;&quot; print(res) 2.2.2.2.3 Expected Average Value - Machiavellianism # conduct main analysis burn_in_RQ1 = 500 ## run MCMC simulation M_avg = sdt[&#39;M_avg&#39;].to_numpy() thetas_M_avg, accept_rates_M_avg = mcmc_mh_posterior(M_avg, 1, target_fun, proposal_fun, proposal_func_prob, n_iter=8000) ## print results of MCMC analysis mcmc_overview(thetas = thetas_M_avg, burn_in = burn_in_RQ1) ## ## -------------------------------------------------- ## RESULTS OF MCMC ANALYIS ## -------------------------------------------------- ## ## Burn-In Period: first 500 ## ## Mode of the Distribution: 3.6934 ## Mean of the Distribution: 3.7082 ## SD of the Distribution: 0.0306 ## Highest Density Interval (95%): [3.648 3.7647] ## ## -------------------------------------------------- ## ## plot results of mcmc analysis r_thetas_M_avg &lt;- unlist(py$thetas_M_avg) r_burn_in_RQ1 &lt;- py$burn_in_RQ1 M_avg_mcmc_plots &lt;- rplotly_mcmcres(data = r_thetas_M_avg, burn_in = r_burn_in_RQ1, theta_name = &quot;Machiavellianism&quot;) M_avg_mcmc_plots$`Full Trace` M_avg_mcmc_plots$`Trace after Burn-In` M_avg_mcmc_plots$`Distribution of Theta` M_avg_mcmc_plots$`Autocorrelation Plot` 2.2.2.2.4 Expected Average Value - Narcissism # conduct main analysis ## run MCMC simulation N_avg = sdt[&#39;N_avg&#39;].to_numpy() thetas_N_avg, accept_rates_N_avg = mcmc_mh_posterior(N_avg, 1, target_fun, proposal_fun, proposal_func_prob, n_iter=8000) ## print results of MCMC analysis mcmc_overview(thetas = thetas_N_avg, burn_in = burn_in_RQ1) ## ## -------------------------------------------------- ## RESULTS OF MCMC ANALYIS ## -------------------------------------------------- ## ## Burn-In Period: first 500 ## ## Mode of the Distribution: 3.0754 ## Mean of the Distribution: 3.0814 ## SD of the Distribution: 0.0336 ## Highest Density Interval (95%): [3.0167 3.1482] ## ## -------------------------------------------------- ## ## plot results of mcmc analysis r_thetas_N_avg &lt;- unlist(py$thetas_N_avg) N_avg_mcmc_plots &lt;- rplotly_mcmcres(data = r_thetas_N_avg, burn_in = r_burn_in_RQ1, theta_name = &quot;Narcissism&quot;) N_avg_mcmc_plots$`Full Trace` N_avg_mcmc_plots$`Trace after Burn-In` N_avg_mcmc_plots$`Distribution of Theta` N_avg_mcmc_plots$`Autocorrelation Plot` 2.2.2.2.5 Expected Average Value - Psychopathy # conduct main analysis ## run MCMC simulation P_avg = sdt[&#39;P_avg&#39;].to_numpy() thetas_P_avg, accept_rates_P_avg = mcmc_mh_posterior(P_avg, 1, target_fun, proposal_fun, proposal_func_prob, n_iter=8000) ## print results of MCMC analysis mcmc_overview(thetas = thetas_P_avg, burn_in = burn_in_RQ1) ## ## -------------------------------------------------- ## RESULTS OF MCMC ANALYIS ## -------------------------------------------------- ## ## Burn-In Period: first 500 ## ## Mode of the Distribution: 2.8560 ## Mean of the Distribution: 2.8438 ## SD of the Distribution: 0.0308 ## Highest Density Interval (95%): [2.7828 2.9004] ## ## -------------------------------------------------- ## ## plot results of mcmc analysis r_thetas_P_avg &lt;- unlist(py$thetas_P_avg) P_avg_mcmc_plots &lt;- rplotly_mcmcres(data = r_thetas_P_avg, burn_in = r_burn_in_RQ1, theta_name = &quot;Narcissism&quot;) P_avg_mcmc_plots$`Full Trace` P_avg_mcmc_plots$`Trace after Burn-In` P_avg_mcmc_plots$`Distribution of Theta` P_avg_mcmc_plots$`Autocorrelation Plot` 2.2.2.2.6 Comparison of Expected Average Values Machiavellianism Narcissism Psychopathy Mean of the Distribution 3.7090 3.0787 2.8430 SD of the Distribution 0.0315 0.0316 0.0313 Highest Density Interval (95%) 3.6498 - 3.7654 3.0189 - 3.1383 2.7835 - 2.9057 Based on the results of the above calculations one can conclude, that the expected average value for Machiavellianism is the highest. 2.3 Bayesian Decision Theory This chapter is written as a practical introduction to Bayesian Decision Theory (BDT). Since I found it easiest to understand the concept of BDT, by directly applying it to real world problems, I devised appropriate scenarios and did just that. The scenarios, all names, organizations and people portrayed in the following examples are fictitious. No identification with actual persons (living or deceased), places, organizations and products is intended or should be inferred. 2.3.1 The Problem at Hand Imagine the following scenario: The NGO “Living with Diabetes” (LwD) provides medical treatment for people with diabetes in regions of the world where insulin is not always readily available and often very expensive. The NGO LwD aims to correctly diagnose diabetes in as many people as possible as quickly as possible. For this very reason LwD conducted a representative study in which data regarding several possible indicators for diabetes was collected. LwD then tasked two independent doctors with the creation of a simple diagnostical model based on that data, that would enable the NGO to quickly and correctly identify patients with diabetes. 2.3.1.1 Model 1 vs Model 2 Doctor A proposed a model (Model 1), in which the Glucose Level and the Body Mass Index of a patient are used as predictors for a positive or negative diabetes diagnosis. Doctor B proposed a model (Model 2), in which the Glucose Level and the Age of a patient are used as predictors for a positive or negative diabetes diagnosis. As staff members of LwD and resident experts in statistics, programming and decision theory it is now our job to decide which diagnostical model LwD should use, to decide when to prescribe insulin. 2.3.1.2 What we have to Work with Both Doctor A and Doctor B provided you with the following: The Dataset used to create Model 1 and Model 2 Distribution Plots for Age, Glucose Level and Body Mass Index Two-Dimensional Histograms for Glucose Level and Age and for Glucose Level and Body Mass Index The results of two multiple logistic regression analyses (frequentist and Bayesian approach) for each model including: Four summary statistics Four plots of the predicted probabilities for a positive Diabetes Diagnosis Four confusion matrices for (cut-off value for classification \\(p=0.5\\)) Four sets of accuracy statistics (cut-off value for classification \\(p=0.5\\)) 2.3.1.2.1 The Dataset 2.3.1.2.1.1 Information about the Dataset Source of Dataset: National Institute of Diabetes and Digestive and Kidney Diseases Objective: Diagnostical prediction of diabetes, based on diagnostic measurements included in the dataset License: CC0: Public Domain Retrieved from: Kaggle 2.3.1.2.1.2 Load Dataset pi_diabetes &lt;- read.csv(&quot;~/Documents/UNIK/UNIK - Psychologie/Master/1. Semester/Bayes-Statistik/Presentation/Data/diabetes.csv&quot;) diab.original &lt;- pi_diabetes 2.3.1.2.1.3 Preprocessing diab &lt;- diab.original fft.diab &lt;- diab # removing those observation rows with 0 in the # variables 2:6 for (i in 2:6) { diab &lt;- diab[-which(diab[, i] == 0), ] } #### names(fft.diab) &lt;- tolower(names(diab.original)) fft.diab$outcome &lt;- as.logical(fft.diab$outcome) #### # scale the predictors for easier comparison of # coefficient posteriors diab$Pregnancies &lt;- scale(diab$Pregnancies) diab$Glucose &lt;- scale(diab$Glucose) diab$BloodPressure &lt;- scale(diab$BloodPressure) diab$SkinThickness &lt;- scale(diab$SkinThickness) diab$Insulin &lt;- scale(diab$Insulin) diab$BMI &lt;- scale(diab$BMI) diab$DiabetesPedigreeFunction &lt;- scale(diab$DiabetesPedigreeFunction) diab$Age &lt;- scale(diab$Age) # modify the data column names slightly for easier # typing names(diab) &lt;- tolower(names(diab.original)) diab$outcome.int &lt;- diab$outcome diab$outcome &lt;- factor(diab$outcome) diab.inspect &lt;- diab 2.3.1.2.1.4 Basic Inspection ## pregnancies glucose bloodpressure skinthickness ## 4 -0.71651083 -1.0896533 -0.37317791 -0.5843629 ## 5 -1.02789913 0.4657189 -2.45382847 0.5567094 ## 7 -0.09373423 -1.4460927 -1.65357826 0.2714413 ## 9 -0.40512253 2.4099341 -0.05307782 1.5076030 ## 14 -0.71651083 2.1507054 -0.85332804 -0.5843629 ## 15 0.52904237 1.4054229 0.10697222 -0.9647204 ## insulin bmi diabetespedigreefunction ## 4 -0.5221747 -0.7095143 -1.0305593 ## 5 0.1005024 1.4249091 5.1085822 ## 7 -0.5726620 -0.2968591 -0.7961084 ## 9 3.2559608 -0.3680065 -1.0566094 ## 14 5.8055711 -0.4249245 -0.3619399 ## 15 0.1594043 -1.0367925 0.1851123 ## age outcome.int ## 4 -0.9670632 0 ## 5 0.2093178 1 ## 7 -0.4769045 1 ## 9 2.1699528 1 ## 14 2.7581434 1 ## 15 1.9738893 1 ## vars n mean sd median ## pregnancies 1 392 0.00 1.00 -0.41 ## glucose 2 392 0.00 1.00 -0.12 ## bloodpressure 3 392 0.00 1.00 -0.05 ## skinthickness 4 392 0.00 1.00 -0.01 ## insulin 5 392 0.00 1.00 -0.26 ## bmi 6 392 0.00 1.00 0.02 ## diabetespedigreefunction 7 392 0.00 1.00 -0.21 ## age 8 392 0.00 1.00 -0.38 ## outcome.int 9 392 0.33 0.47 0.00 ## trimmed mad min max range ## pregnancies -0.15 0.46 -1.03 4.27 5.29 ## glucose -0.07 1.01 -2.16 2.44 4.60 ## bloodpressure 0.01 0.95 -3.73 3.15 6.88 ## skinthickness -0.02 1.13 -2.11 3.22 5.33 ## insulin -0.17 0.68 -1.20 5.81 7.00 ## bmi -0.04 0.95 -2.12 4.84 6.96 ## diabetespedigreefunction -0.14 0.82 -1.27 5.49 6.76 ## age -0.16 0.73 -0.97 4.91 5.88 ## outcome.int 0.29 0.00 0.00 1.00 1.00 ## skew kurtosis se ## pregnancies 1.33 1.43 0.05 ## glucose 0.51 -0.51 0.05 ## bloodpressure -0.09 0.75 0.05 ## skinthickness 0.21 -0.48 0.05 ## insulin 2.15 6.21 0.05 ## bmi 0.66 1.50 0.05 ## diabetespedigreefunction 1.94 6.22 0.05 ## age 1.39 1.68 0.05 ## outcome.int 0.71 -1.50 0.02 2.3.1.2.1.5 Scatter Plot Matrix (SPLOM) 2.3.1.2.2 Distribution Plots of Relevant Variables 2.3.1.2.3 Two-Dimensional Histograms of Relevant Variables 2.3.1.2.4 Frequentist Approach to MLR 2.3.1.2.4.1 Model 1: Diabetes Diagnosis ~ Glucose Level + BMI pred1.1.diab &lt;- glm(formula = outcome ~ glucose + bmi, data = diab, family = binomial) odds.pred1.1.diab &lt;- exp(coef(pred1.1.diab)) #calculating odds ratio (OR) conf.int.or.m1.1 &lt;- exp(confint(pred1.1.diab)) #confidence intervalls of OR (If CI of OR includes 1 -&gt; not significant) diab.lr.fr &lt;- diab diab.lr.fr$prob.pred1.1.diab &lt;- pred1.1.diab$fitted.values #fitted values show the probabilities measured based on the model diab.plot &lt;- diab.lr.fr diab.plot$glucose &lt;- as.numeric(diab.plot$glucose) diab.plot$bmi &lt;- as.numeric(diab.plot$bmi) model1.1.plot &lt;- plot_ly(diab.plot, x = ~glucose, y = ~bmi, z = ~outcome, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Recorded Diabetes\\nDiagnosis&quot;, marker = list(size = 3, color = &quot;#90527a&quot;)) model1.1.plot &lt;- model1.1.plot %&gt;% add_trace(diab.plot, x = ~glucose, y = ~bmi, z = ~prob.pred1.1.diab, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Predicted Propability\\nof Diabetes Diagnosis\\n(Frequentist Approach)&quot;, marker = list(size = 3, color = &quot;#f4cccc&quot;)) model1.1.plot &lt;- model1.1.plot %&gt;% layout(title = list(text = &quot;Model 1: Diabetes Diagnosis ~ Glucose Level + BMI&quot;, y = 0.95), scene = list(xaxis = list(title = &quot;Glucose Level [scaled]&quot;), yaxis = list(title = &quot;Body Mass Index [scaled]&quot;), zaxis = list(title = &quot;Diabetes Diagnosis [scaled]&quot;, nticks = 11, range = c(0, 1))), legend = list(y = 0.05)) 2.3.1.2.4.2 Model 2: Diabetes Diagnosis ~ Glucose Level + Insulin Level pred2.1.diab &lt;- glm(formula = outcome ~ glucose + age, data = diab, family = binomial) odds.pred2.1.diab &lt;- exp(coef(pred2.1.diab)) #calculating odds ratio (OR) conf.int.or.m2.1 &lt;- exp(confint(pred2.1.diab)) #confidence intervalls of OR (If CI of OR includes 1 -&gt; not significant) diab.lr.fr$prob.pred2.1.diab &lt;- pred2.1.diab$fitted.values #fitted values show the probabilities measured based on the model diab.plot$prob.pred2.1.diab &lt;- diab.lr.fr$prob.pred2.1.diab diab.plot$age &lt;- as.numeric(diab.plot$age) model2.1.plot &lt;- plot_ly(diab.plot, x = ~glucose, y = ~age, z = ~outcome, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Recorded Diabetes\\nDiagnosis&quot;, marker = list(size = 3, color = &quot;#90527a&quot;)) model2.1.plot &lt;- model2.1.plot %&gt;% add_trace(diab.plot, x = ~glucose, y = ~age, z = ~prob.pred2.1.diab, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Predicted Propability\\nof Diabetes Diagnosis\\n(Frequentist Approach)&quot;, marker = list(size = 3, color = &quot;#c0d6e4&quot;)) model2.1.plot &lt;- model2.1.plot %&gt;% layout(title = list(text = &quot;Model 2: Diabetes Diagnosis ~ Glucose Level + Age&quot;, y = 0.95), scene = list(xaxis = list(title = &quot;Glucose Level [scaled]&quot;), yaxis = list(title = &quot;Age [scaled]&quot;), zaxis = list(title = &quot;Diabetes Diagnosis [scaled]&quot;, nticks = 11, range = c(0, 1))), legend = list(y = 0.05)) 2.3.1.2.4.3 Results of MLR Analyses 2.3.1.2.4.3.1 Model 1: Summary Statistics and Plot of Predicted Values summary(pred1.1.diab) ## ## Call: ## glm(formula = outcome ~ glucose + bmi, family = binomial, data = diab) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.2112 -0.7396 -0.4114 0.7009 2.4306 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.9335 0.1344 -6.945 3.78e-12 *** ## glucose 1.2564 0.1489 8.437 &lt; 2e-16 *** ## bmi 0.5045 0.1378 3.662 0.00025 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 498.10 on 391 degrees of freedom ## Residual deviance: 372.12 on 389 degrees of freedom ## AIC: 378.12 ## ## Number of Fisher Scoring iterations: 4 model1.1.plot 2.3.1.2.4.3.2 Model 2: Summary Statistics and Plot of Predicted Values summary(pred2.1.diab) ## ## Call: ## glm(formula = outcome ~ glucose + age, family = binomial, data = diab) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.2222 -0.6984 -0.4333 0.7519 2.4180 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.9166 0.1339 -6.847 7.55e-12 *** ## glucose 1.1794 0.1493 7.899 2.81e-15 *** ## age 0.5158 0.1332 3.872 0.000108 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 498.10 on 391 degrees of freedom ## Residual deviance: 370.69 on 389 degrees of freedom ## AIC: 376.69 ## ## Number of Fisher Scoring iterations: 4 model2.1.plot diab.lr.fr$m1.class.cop0.5 &lt;- ifelse(diab.lr.fr$prob.pred1.1.diab &gt; 0.5, 1, 0) # if predicted probability is &gt; 0.5, assign &#39;positive diabetes diagnosis&#39; (=1), if &lt; 0.4, then assign &#39;negative diabetes diagnosis&#39; (=0) diab.lr.fr$m2.class.cop0.5 &lt;- ifelse(diab.lr.fr$prob.pred2.1.diab &gt; 0.5, 1, 0) fr.model1.pred.pos.rec.pos &lt;- nrow(diab.lr.fr[diab.lr.fr$m1.class.cop0.5 == 1 &amp; diab.lr.fr$outcome == &quot;1&quot;, ]) fr.model1.pred.neg.rec.pos &lt;- nrow(diab.lr.fr[diab.lr.fr$m1.class.cop0.5 == 0 &amp; diab.lr.fr$outcome == &quot;1&quot;, ]) fr.model1.pred.pos.rec.neg &lt;- nrow(diab.lr.fr[diab.lr.fr$m1.class.cop0.5 == 1 &amp; diab.lr.fr$outcome == &quot;0&quot;, ]) fr.model1.pred.neg.rec.neg &lt;- nrow(diab.lr.fr[diab.lr.fr$m1.class.cop0.5 == 0 &amp; diab.lr.fr$outcome == &quot;0&quot;, ]) fr.model1.hits &lt;- fr.model1.pred.pos.rec.pos fr.model1.misses &lt;- fr.model1.pred.neg.rec.pos fr.model1.false.alarms &lt;- fr.model1.pred.pos.rec.neg fr.model1.correct.rejections &lt;- fr.model1.pred.neg.rec.neg ########## fr.model2.pred.pos.rec.pos &lt;- nrow(diab.lr.fr[diab.lr.fr$m2.class.cop0.5 == 1 &amp; diab.lr.fr$outcome == &quot;1&quot;, ]) fr.model2.pred.neg.rec.pos &lt;- nrow(diab.lr.fr[diab.lr.fr$m2.class.cop0.5 == 0 &amp; diab.lr.fr$outcome == &quot;1&quot;, ]) fr.model2.pred.pos.rec.neg &lt;- nrow(diab.lr.fr[diab.lr.fr$m2.class.cop0.5 == 1 &amp; diab.lr.fr$outcome == &quot;0&quot;, ]) fr.model2.pred.neg.rec.neg &lt;- nrow(diab.lr.fr[diab.lr.fr$m2.class.cop0.5 == 0 &amp; diab.lr.fr$outcome == &quot;0&quot;, ]) fr.model2.hits &lt;- fr.model2.pred.pos.rec.pos fr.model2.misses &lt;- fr.model2.pred.neg.rec.pos fr.model2.false.alarms &lt;- fr.model2.pred.pos.rec.neg fr.model2.correct.rejections &lt;- fr.model2.pred.neg.rec.neg 2.3.1.2.4.4 Confusion Matrices - Cut-Off Value for Classification \\(p=0.5\\) Model 1 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 69 Hits 28 False Alarms Predicted Diagnosis NEGATIVE 61 Misses 234 Correct Rejections Model 2 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 74 Hits 29 False Alarms Predicted Diagnosis NEGATIVE 56 Misses 233 Correct Rejections 2.3.1.2.4.5 Accuracy Statistics Accuracy - Probability of correctly identifying any case \\[ {accuracy} = \\frac{hits + {correct~rejections}}{hits + {false~alarms} + misses + {correct~rejections}} \\] Sensitivity - Probability of correctly identifying a true positive case \\[ sensitivity = \\frac{hits}{hits + misses} \\] Specificity - Probability of correctly identifying a true negative case \\[ specificity = \\frac{{correct~rejections}}{{correct~rejections} + {false~alarms}} \\] Weighted Accuracy - Weighted average of sensitivity and specificity dictated by a sensitivity weighting parameter \\(w\\) \\[ {weighted~accuracy} = sensitivity \\times w + specificity \\times (1-w) \\] Balanced Accuracy - Average of sensitivity and specificity (i.e., weighted accuracy with \\(w = 0.5\\)) \\[ {balanced~accuracy} = sensitivity \\times 0.5 + specificity \\times 0.5 \\] fr.model1.acc &lt;- (fr.model1.hits + fr.model1.correct.rejections)/(fr.model1.hits + fr.model1.false.alarms + fr.model1.misses + fr.model1.correct.rejections) fr.model1.sens &lt;- fr.model1.hits/(fr.model1.hits + fr.model1.misses) fr.model1.spec &lt;- fr.model1.correct.rejections/(fr.model1.false.alarms + fr.model1.correct.rejections) fr.model1.bacc &lt;- fr.model1.sens * 0.5 + fr.model1.spec * 0.5 ########### fr.model2.acc &lt;- (fr.model2.hits + fr.model2.correct.rejections)/(fr.model2.hits + fr.model2.false.alarms + fr.model2.misses + fr.model2.correct.rejections) fr.model2.sens &lt;- fr.model2.hits/(fr.model2.hits + fr.model2.misses) fr.model2.spec &lt;- fr.model2.correct.rejections/(fr.model2.false.alarms + fr.model2.correct.rejections) fr.model2.bacc &lt;- fr.model2.sens * 0.5 + fr.model2.spec * 0.5 Cut-Off Value \\(p=0.5\\) Model 1 Model 2 \\(\\Delta\\) Accuracy 0.7729592 0.7831633 0.0102041 Sensitivity 0.5307692 0.5692308 0.0384616 Specificity 0.8931298 0.889313 -0.0038168 Balanced Accuracy 0.7119495 0.7292719 0.0173224 2.3.1.2.5 Bayesian Approach to MLR 2.3.1.2.5.1 Model 1: Diabetes Diagnosis ~ Glucose Level + BMI options(mc.cores = parallel::detectCores()) t_prior &lt;- student_t(df = 7, location = 0, scale = 2.5) post.model1.1 &lt;- stan_glm(outcome ~ glucose + bmi, data = diab, family = binomial(link = &quot;logit&quot;), prior = t_prior, prior_intercept = t_prior, QR = TRUE, seed = 77) mcmc_trace(post.model1.1) mcmc_dens_overlay(post.model1.1) mcmc_acf(post.model1.1) pp.diab.model1.1 &lt;- posterior_predict(post.model1.1, newdata = diab, seed = 77) diabetes.predictions.model1.1 &lt;- diab %&gt;% mutate(probability.pos.diab.diagnosis = colMeans(pp.diab.model1.1), probability.neg.diab.diagnosis = 1 - colMeans(pp.diab.model1.1), classification.cutoff0.5 = as.numeric(probability.pos.diab.diagnosis &gt;= 0.5)) %&gt;% select(glucose, bmi, probability.pos.diab.diagnosis, probability.neg.diab.diagnosis, classification.cutoff0.5, outcome) diab.plot$prob.pred.1.1.bay &lt;- diabetes.predictions.model1.1$probability.pos.diab.diagnosis model1.1.plot2 &lt;- model1.1.plot model1.1.plot2 &lt;- model1.1.plot2 %&gt;% add_trace(diab.plot, x = ~glucose, y = ~bmi, z = diab.plot$prob.pred.1.1.bay, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Predicted Propability\\nof Diabetes Diagnosis\\n(Bayesian Approach)&quot;, marker = list(size = 3, color = &quot;#e68d8d&quot;)) 2.3.1.2.5.2 Model 2: Diabetes Diagnosis ~ Glucose Level + Age options(mc.cores = parallel::detectCores()) post.model2.1 &lt;- stan_glm(outcome ~ glucose + age, data = diab, family = binomial(link = &quot;logit&quot;), prior = t_prior, prior_intercept = t_prior, QR = TRUE, seed = 77) mcmc_trace(post.model2.1) mcmc_dens_overlay(post.model2.1) mcmc_acf(post.model2.1) pp.diab.model2.1 &lt;- posterior_predict(post.model2.1, newdata = diab, seed = 77) diabetes.predictions.model2.1 &lt;- diab %&gt;% mutate(probability.pos.diab.diagnosis = colMeans(pp.diab.model2.1), probability.neg.diab.diagnosis = 1 - colMeans(pp.diab.model2.1), classification.cutoff0.5 = as.numeric(probability.pos.diab.diagnosis &gt;= 0.5)) %&gt;% select(glucose, insulin, probability.pos.diab.diagnosis, probability.neg.diab.diagnosis, classification.cutoff0.5, outcome) diab.plot$prob.pred.2.1.bay &lt;- diabetes.predictions.model2.1$probability.pos.diab.diagnosis model2.1.plot2 &lt;- model2.1.plot model2.1.plot2 &lt;- model2.1.plot2 %&gt;% add_trace(diab.plot, x = ~glucose, y = ~age, z = diab.plot$prob.pred.2.1.bay, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Predicted Propability\\nof Diabetes Diagnosis\\n(Bayesian Approach)&quot;, marker = list(size = 3, color = &quot;#8ab3cd&quot;)) 2.3.1.2.5.3 Results of MLR Analyses 2.3.1.2.5.3.1 Model 1: Posterior Distributions for Parameters pplot1.1 &lt;- plot(post.model1.1, &quot;areas&quot;, prob = 0.95, prob_outer = 1) pplot1.1 + geom_vline(xintercept = 0) posterior_interval(post.model1.1, prob = 0.95) ## 2.5% 97.5% ## (Intercept) -1.2109934 -0.6764719 ## glucose 0.9810390 1.5809497 ## bmi 0.2376162 0.7766815 2.3.1.2.5.3.2 Model 1: Summary Statistics and Plot of Predicted Values summary(post.model1.1) ## ## Model Info: ## function: stan_glm ## family: binomial [logit] ## formula: outcome ~ glucose + bmi ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 392 ## predictors: 3 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) -0.9 0.1 -1.1 -0.9 -0.8 ## glucose 1.3 0.1 1.1 1.3 1.5 ## bmi 0.5 0.1 0.3 0.5 0.7 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 0.3 0.0 0.3 0.3 0.4 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3228 ## glucose 0.0 1.0 3527 ## bmi 0.0 1.0 3293 ## mean_PPD 0.0 1.0 3539 ## log-posterior 0.0 1.0 1916 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). model1.1.plot2 2.3.1.2.5.3.3 Model 2: Posterior Distributions for Parameters pplot2.1 &lt;- plot(post.model2.1, &quot;areas&quot;, prob = 0.95, prob_outer = 1) pplot2.1 + geom_vline(xintercept = 0) posterior_interval(post.model2.1, prob = 0.95) ## 2.5% 97.5% ## (Intercept) -1.1831074 -0.6627571 ## glucose 0.9027726 1.4772402 ## age 0.2631176 0.7776975 2.3.1.2.5.3.4 Model 2: Summary Statistics and Plot of Predicted Values summary(post.model2.1) ## ## Model Info: ## function: stan_glm ## family: binomial [logit] ## formula: outcome ~ glucose + age ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 392 ## predictors: 3 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) -0.9 0.1 -1.1 -0.9 -0.7 ## glucose 1.2 0.1 1.0 1.2 1.4 ## age 0.5 0.1 0.4 0.5 0.7 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 0.3 0.0 0.3 0.3 0.4 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 3039 ## glucose 0.0 1.0 3441 ## age 0.0 1.0 3624 ## mean_PPD 0.0 1.0 3277 ## log-posterior 0.0 1.0 1862 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). model2.1.plot2 2.3.1.2.5.4 Confusion Matrices - Cut-Off Value for Classification \\(p=0.5\\) model1.co0.5.pred.pos.rec.pos &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.cutoff0.5 == 1 &amp; diabetes.predictions.model1.1$outcome == &quot;1&quot;, ]) model1.co0.5.pred.neg.rec.pos &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.cutoff0.5 == 0 &amp; diabetes.predictions.model1.1$outcome == &quot;1&quot;, ]) model1.co0.5.pred.pos.rec.neg &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.cutoff0.5 == 1 &amp; diabetes.predictions.model1.1$outcome == &quot;0&quot;, ]) model1.co0.5.pred.neg.rec.neg &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.cutoff0.5 == 0 &amp; diabetes.predictions.model1.1$outcome == &quot;0&quot;, ]) model1.co0.5.hits &lt;- model1.co0.5.pred.pos.rec.pos model1.co0.5.misses &lt;- model1.co0.5.pred.neg.rec.pos model1.co0.5.false.alarms &lt;- model1.co0.5.pred.pos.rec.neg model1.co0.5.correct.rejections &lt;- model1.co0.5.pred.neg.rec.neg ########### model2.co0.5.pred.pos.rec.pos &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.cutoff0.5 == 1 &amp; diabetes.predictions.model2.1$outcome == &quot;1&quot;, ]) model2.co0.5.pred.neg.rec.pos &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.cutoff0.5 == 0 &amp; diabetes.predictions.model2.1$outcome == &quot;1&quot;, ]) model2.co0.5.pred.pos.rec.neg &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.cutoff0.5 == 1 &amp; diabetes.predictions.model2.1$outcome == &quot;0&quot;, ]) model2.co0.5.pred.neg.rec.neg &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.cutoff0.5 == 0 &amp; diabetes.predictions.model2.1$outcome == &quot;0&quot;, ]) model2.co0.5.hits &lt;- model2.co0.5.pred.pos.rec.pos model2.co0.5.misses &lt;- model2.co0.5.pred.neg.rec.pos model2.co0.5.false.alarms &lt;- model2.co0.5.pred.pos.rec.neg model2.co0.5.correct.rejections &lt;- model2.co0.5.pred.neg.rec.neg Model 1 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 69 Hits 28 False Alarms Predicted Diagnosis NEGATIVE 61 Misses 234 Correct Rejections Model 2 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 74 Hits 28 False Alarms Predicted Diagnosis NEGATIVE 56 Misses 234 Correct Rejections 2.3.1.2.5.5 Accuracy Statistics model1.co0.5.acc &lt;- (model1.co0.5.hits + model1.co0.5.correct.rejections)/(model1.co0.5.hits + model1.co0.5.false.alarms + model1.co0.5.misses + model1.co0.5.correct.rejections) model1.co0.5.sens &lt;- model1.co0.5.hits/(model1.co0.5.hits + model1.co0.5.misses) model1.co0.5.spec &lt;- model1.co0.5.correct.rejections/(model1.co0.5.false.alarms + model1.co0.5.correct.rejections) model1.co0.5.bacc &lt;- model1.co0.5.sens * 0.5 + model1.co0.5.spec * 0.5 ########### model2.co0.5.acc &lt;- (model2.co0.5.hits + model2.co0.5.correct.rejections)/(model2.co0.5.hits + model2.co0.5.false.alarms + model2.co0.5.misses + model2.co0.5.correct.rejections) model2.co0.5.sens &lt;- model2.co0.5.hits/(model2.co0.5.hits + model2.co0.5.misses) model2.co0.5.spec &lt;- model2.co0.5.correct.rejections/(model2.co0.5.false.alarms + model2.co0.5.correct.rejections) model2.co0.5.bacc &lt;- model2.co0.5.sens * 0.5 + model2.co0.5.spec * 0.5 Cut-Off Value \\(p=0.5\\) Model 1 Model 2 \\(\\Delta\\) Accuracy 0.7729592 0.7857143 0.0127551 Sensitivity 0.5307692 0.5692308 0.0384616 Specificity 0.8931298 0.8931298 0 Balanced Accuracy 0.7119495 0.7311803 0.0192308 2.3.2 Model Selection based on Accuracy Statistics Cut-Off Value \\(p=0.5\\) M1F M2F \\(\\Delta_F\\) M1B M2B \\(\\Delta_B\\) Acc 0.7729592 0.7831633 0.0102041 0.7729592 0.7857143 0.0127551 Sens 0.5307692 0.5692308 0.0384616 0.5307692 0.5692308 0.0384616 Spec 0.8931298 0.889313 -0.0038168 0.8931298 0.8931298 0 Bacc 0.7119495 0.7292719 0.0173224 0.7119495 0.7311803 0.0192308 2.3.2.1 Remember What We Set Out to Do! We were tasked by our employer “Living with Diabetes” to decide which diagnostical model LwD should use, to decide when to prescribe insulin. Since the model, that we choose, will be used in practical setting, in which insulin is not always readily available and often very expensive, our decision should minimize the number of false alarms. Thus our decision should favour the model with the greater specificity. 2.3.2.2 Which Model Should We Choose? The accuracy statistics (calculated based on the results of the frequentist as well as the Bayesian MLR) show, that the first and the second model both have nearly the same specificity. Therefore we cannot base our decision on the comparison of the specificity of the two models. Based on the assumption, that both models fit the data equally well and in the absence of further information, we would base our decision now solely on the differences in accuracy and sensitive of the two models. This would lead us to choose the second model, since it has a slightly higher accuracy (ca. \\(1\\%\\) higher probability to correctly identify any case) and a somewhat higher sensitivity (ca. \\(3\\%\\) higher probability to correctly identify a true positive case). 2.3.2.3 A Truly Frustrating Result! Initially we had hoped, that one of the models would have a specificity of at least \\(0.95\\) (\\(95\\%\\) probability to correctly identify a true negative case). Unfortunately neither model met our expectations. A Frequentist would now probably report these results back to the executives at LwD and recommend, that the doctors try to come up with new models with at least the same model fit and accuracy but a higher specificity. 2.3.3 What is Bayesian Decision Theory? Since we are Bayesians though, there is a another possibility: By applying Bayesian decision theory we can adapt the decisions we make based on the probabilities predicted by our models to the practical setting, in which the models shall be applied. 2.3.3.1 Normative Decision Theory Before we do that though, lets review some basic concepts of normative decision theory (NDT). Normative decision theory tells us how to make rational decisions under uncertainty. According to the NDT a decision is rational, if … all information necessary to reach the decision is processed correctly, the decision was made in accordance with the goal-system of the decider and the decision maximizes utility or minimizes loss. That means, that in order to make a rational decision we must first gather all necessary data. Having done that, we need to processes the information correctly. In cases in which we want to make a judgement about the likelihood of something, we should use Bayes’ theorem according to NDT. Furthermore our decision needs to be made in accordance with our goal-system. In other words the decision we make must reflect the goals, that we want to achieve by making said decision. Lastly our decision must be made in such a way, that it maximizes positive outcomes (utility) or minimizes negative outcomes (loss). 2.3.3.2 What’s So Bayesian About That? Bayesian Decision Theory is basically the statistical application of the concepts of NDT to the problem of pattern classification, i.e. the categorization of data into distinct classes. This categorization can take the form of either the distinct labelling of data (e.g. “diabetic” vs “non-diabetic”), the division of data into a number of classes (e.g. “Iris setosa” vs “Iris versicolor” vs “Iris virginica”), the selection of the most significant feature(s) of data or some combination of one or more of these tasks. 2.3.3.3 What Do We Do Now? Before we continue, let us recap what we have done so far: We have gathered the necessary information (see dataset) and processed it correctly (Bayesian MLR Analysis). We have defined our goal: Classify patients as “diabetic” or “non-diabetic” based on our models in a way, that minimizes the number of false alarms. Now all we have to do is to find a way to reach our goal and we do that by creating and applying appropriate loss functions. 2.3.3.4 Loss Functions Loss functions are simple mathematical functions that formalize the relationship between a decision and its loss depending on whether the decision is correct or false. In this context loss can be understood as the penalty we assign to the deviation of our decision from the correct decision. If our decision is correct though the loss is zero. In order to illustrate how loss functions work let us consider the following example in which one wants to make a point estimate of an unknown parameter. 2.3.3.4.1 Guessing Future Sales of TacBook Pro Laptops Max works in an Pear Store. Due to the ongoing recession their boss is concerned about future sales and wants to know exactly how many TacBook Pro laptops will be sold per month. Recently a consultant was tasked with analysing past sales of high-priced items. Said analyst provided Max with a distribution of the number of TacBook Pro laptops the Pear Store will sell per month (posterior distribution). Since their Boss does not understand Bayesian statistics at all they want them to report a single number for the number of TacBook Pro laptops the Pear Store will sell per month. A histogram as well as a violin plot of the aforementioned posterior distribution is shown below. pd.id &lt;- c(1:51) tacbp.sales &lt;- c(4, 19, 20, 23, 23, 25, 25, 26, 27, 28, 28, 28, 29, 30, 32, 32, 32, 32, 32, 33, 33, 33, 33, 34, 34, 34, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 38, 38, 39, 40, 40, 41, 41, 45, 47, 47, 47, 49) pear.store.sales &lt;- data.frame(pd.id, tacbp.sales) pear.mean &lt;- mean(pear.store.sales$tacbp.sales) pear.median &lt;- median(pear.store.sales$tacbp.sales) pear.mode &lt;- 35 pear.hist &lt;- plot_ly(pear.store.sales, x = ~tacbp.sales, type = &quot;histogram&quot;, nbinsx = 50, marker = list(color = &quot;#f4cccc&quot;, line = list(color = &quot;#e68d8d&quot;, width = 2)), hovertemplate = paste(&quot;&lt;b&gt;Predicted Sales&lt;/b&gt;: %{x}&quot;, &quot;&lt;br&gt;&lt;b&gt;Occurences&lt;/b&gt;: %{y}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;), name = &quot;H&quot;) %&gt;% layout(title = &quot;Posterior Distribution - Pear Store Sales&quot;, xaxis = list(title = &quot;Number of TacBook Pro Laptops Sold&quot;, nticks = 11, range = c(0, 50)), yaxis = list(title = &quot;Number of Occurences&quot;, zeroline = FALSE, nticks = 8, range = c(0, 7))) pear.violin &lt;- plot_ly(pear.store.sales, x = ~tacbp.sales, type = &quot;violin&quot;, name = &quot;VP&quot;, box = list(visible = T), meanline = list(visible = T), marker = list(color = &quot;#e68d8d&quot;), fillcolor = &quot;#c0d6e4&quot;, line = list(color = &quot;#8ab3cd&quot;), box = list(fillcolor = &quot;#c0d6e4&quot;, line = list(color = &quot;#8ab3cd&quot;))) pear.subp &lt;- subplot(pear.violin, pear.hist, nrows = 2, heights = c(0.4, 0.6), shareX = TRUE, titleX = TRUE, titleY = TRUE, margin = 0.01) %&gt;% layout(showlegend = FALSE, margin = list(l = 75, r = 75, b = 75, t = 75)) pear.subp Seeing a visualization of the posterior distribution Max makes an (somewhat educated) guess regarding future sales and tell their boss, that they will sell 34 TacBook Pro Laptops per month (\\(g = 34\\)). In order to find out though, if Max’ guess was actually the best one, we have to follow these three steps: Choose an appropriate loss function. Calculate the loss for the guess Max has made (\\(L(34)\\)). Compare said loss \\(L(34)\\) to the losses for all other reasonable guesses. 2.3.3.4.2 The Appropriate Loss Function Before deciding on which loss function to use, let me first introduce three very popular loss functions, that are used in a wide variety of contexts. 2.3.3.4.2.1 The 0/1 Loss Function \\[ L_{0,i}(0,g)= \\begin{cases} 0 &amp;\\text{if $g=x_i$}\\\\ 1 &amp;\\text{otherwise} \\end{cases} \\] The 0/1 loss function (\\(L_0\\)) assigns the same loss to every incorrect decision or guess. It does not matter how much the incorrect decision deviates from the correct one, the loss is the same. This loss function is appropriate in cases in which only the correct decision is acceptable. An example would be guessing, whether there is a bomb in a suitcase or not. Only the correct guess is an acceptable one. 2.3.3.4.2.2 The Quadratic Loss Function \\[ L_2(g) = \\sum_{i=1}^n (x_i-g)^2 \\] The quadratic loss function (\\(L_2\\)) should look very familiar, since it uses the sum of squared errors to calculate the the loss of a decision or guess. It is exactly that term, whose value we try to minimize, when performing a linear regression analysis. This loss function heavily penalizes large deviations from the correct decision. For this reason one could for example easily imagine using the \\(L_2\\) when estimating the life expectancy of a terminally ill patient. 2.3.3.4.2.3 The Linear Loss Function \\[ L_1(g) = \\sum_{i=1}^n |x_i-g| \\] The linear loss function (\\(L_1\\)) assumes a linear relationship between the degree of deviation of incorrect decisions and their losses. Imagine the following scenario: A person participates in a contest in which they are given 100 Euros. Said person is now asked to guess the number of red jelly beans in a jar filled with jelly beans of all different colours. If they guess the correct number (50), they get to keep their money. If their guess is off by 10 though, they loose 10 Euro. If their guess is off by 20, they loose 20 Euro. In this example a guess, that differs twice as much from the correct answer as another guess, results in the loss of twice as much money. Since the degree of deviation of Max’ guess does matter, it is not advisable in my opinion to use \\(L_0\\) in the aforementioned scenario. Furthermore I do not think it reasonable to use the \\(L_2\\) in this context, since it would penalize larger deviations too heavily. Therefore we shall use the linear loss function (\\(L_1\\)) to calculate the loss of Max’ guess. 2.3.3.4.3 Calculating the Loss of Max’ Guess In order to calculate the total loss of Max’ guess using the \\(L_1\\) we simply sum up the absolute deviations of their guess from each and every value in the posterior distribution. pear.store.sales &lt;- pear.store.sales %&gt;% add_column(MaxL1g34 = NA, .after = &quot;tacbp.sales&quot;) for (i in 1:length(pear.store.sales$pd.id)) { pear.store.sales$MaxL1g34[i] &lt;- abs(pear.store.sales$tacbp.sales[i] - 34) } MaxTL1g34 &lt;- sum(pear.store.sales$MaxL1g34) MaxTL1g34 ## [1] 282 2.3.3.4.4 Comparing Losses j &lt;- c(0:50) j.names &lt;- paste0(&quot;g&quot;, 0:50) a &lt;- rep(NA, 51) all.guesses.all.losses &lt;- data.frame(a) all.guesses.all.losses[, j.names] &lt;- NA all.guesses.all.losses &lt;- all.guesses.all.losses[, -1] for (k in 1:length(all.guesses.all.losses$g0)) { for (i in 1:length(all.guesses.all.losses$g0)) { all.guesses.all.losses[i, k] &lt;- abs(pear.store.sales$tacbp.sales[i] - j[k]) } } guess &lt;- 0:50 total.losses &lt;- as.numeric(mapply(sum, all.guesses.all.losses[, 1:51])) losses &lt;- data.frame(guess, total.losses) losses.plot &lt;- plot_ly(losses, x = ~guess, y = ~total.losses, type = &quot;scatter&quot;, mode = &quot;lines+markers&quot;, hovertemplate = paste(&quot;&lt;b&gt;Guess&lt;/b&gt;: %{x}&quot;, &quot;&lt;br&gt;&lt;b&gt;Loss&lt;/b&gt;: %{y}&quot;, &quot;&lt;extra&gt;&lt;/extra&gt;&quot;), line = list(color = &quot;#c0d6e4&quot;), marker = list(color = &quot;#8ab3cd&quot;), name = &quot;L&quot;) %&gt;% layout(yaxis = list(title = &quot;Loss - &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;&quot;, zeroline = FALSE, nticks = 4, range = c(200, 1600))) pear.subp2 &lt;- subplot(pear.violin, losses.plot, pear.hist, nrows = 3, heights = c(0.3, 0.3, 0.4), shareX = TRUE, titleX = TRUE, titleY = TRUE, margin = 0.01) %&gt;% layout(showlegend = FALSE, margin = list(l = 75, r = 75, b = 75, t = 75)) pear.subp2 2.3.3.4.5 Congratulations to Max We see that when using the linear loss function \\(L_1\\) the total loss is smallest for a point estimate of 34 \\(g=34\\): \\[ L_1(34) = \\sum_{i=1}^{50} |x_i-34| = 282 \\] We can of course only guess why Max made this particular guess, but it might be because they had some knowledge about Bayesian statistics. Maybe they knew that the \\(L_1\\) might arguably the best choice in this scenario. Maybe they knew as well, that the \\(L_1\\) always favours the median of a distribution and chose the a point estimate of 34, precisely because it is the median of the distribution. 2.3.3.4.6 Good to Know Different loss functions favour different distribution parameters. The 0/1 loss function (\\(L_0\\)) favours the mode of the distribution. The quadratic loss function (\\(L_2\\)) favours the mean of the distribution. The linear loss function (\\(L_1\\)) favours the median of the distribution. 2.3.4 Creating the Appropriate Loss Functions Now that we understand how loss functions work let us get back to the problem at hand. We know that we need to find or create a loss function, that reduces the number of false alarms considerably, when classifying patients as either “diabetic” or “non-diabetic”. Unlike in our example though, where Max made one guess (point estimation) or one decision, we now have to weigh two decisions against each other. 2.3.4.1 Possible Decisions \\(d_1\\): Accept \\(H_1\\) (Patient is diabetic) - Decide that patient has diabetes \\(d_2\\): Accept \\(H_2\\) (Patient is not diabetic)- Decide that patient does not have diabetes Since we have two weigh these two decisions against each other, we create a loss function for \\(d_1\\) as well as for \\(d_2\\). 2.3.4.2 Loss Functions for \\(d_1\\) and \\(d_2\\) \\[ L(d_1)= \\begin{cases} loss_{Hit} &amp;\\text{if $d_1$ is right}\\\\ loss_{False~Alarm} &amp;\\text{if $d_1$ is wrong} \\end{cases} \\] \\[ L(d_2)= \\begin{cases} loss_{Correct~Rejection} &amp;\\text{if $d_2$ is right}\\\\ loss_{Miss} &amp;\\text{if $d_2$ is wrong} \\end{cases} \\] 2.3.4.3 Defining Losses Having done that, we can now assign values to \\(loss_{Hit}\\), \\(loss_{False~Alarm}\\), \\(loss_{Correct~Rejection}\\) and \\(loss_{Miss}\\). We do not want to penalize correct decisions - hits and correct rejections - and therefore do not assign any loss to them. On the other hand though, we want to penalize incorrect decisions - false alarms and misses. Thus we assign non-zero values to \\(loss_{False~Alarm}\\) and \\(loss_{Miss}\\). Since we want to penalize false alarms more heavily than misses we assign a value to \\(loss_{False~Alarm}\\), that is greater than the value, which we assign to \\(loss_{Miss}\\). \\(Loss_{False~Alarm} = f = 20\\) \\(Loss_{Correct~Rejection} = 0\\) \\(Loss_{Hit} = 0\\) \\(Loss_{Miss} = m = 10\\) The resulting loss functions are shown below: \\[ L(d_1)= \\begin{cases} 0 &amp;\\text{if $d_1$ is right}\\\\ f = 20 &amp;\\text{if $d_1$ is wrong} \\end{cases} \\] \\[ L(d_2)= \\begin{cases} 0 &amp;\\text{if $d_2$ is right}\\\\ m = 10 &amp;\\text{if $d_2$ is wrong} \\end{cases} \\] 2.3.5 Calculating the Expected Losses for \\(d_1\\) and \\(d_2\\) Having defined the loss functions for \\(d_1\\) and \\(d_2\\), we can now calculate the expected losses for these two decisions for the first and the second model. In order to calculate the expected loss for the decision, that a patient has diabetes (\\(E[L(d_1)]\\)), we add the product of \\(loss_{Hit}\\) and the probability of \\(H_1\\) given our data and the the product of \\(loss_{False~Alarm}\\) and the probability of \\(H_2\\) given our data together. Since \\(loss_{Hit} = 0\\), \\(E[L(d_1)]\\) equals the product of \\(loss_{False~Alarm}\\) and the probability of \\(H_2\\) given our data. \\[ E[L(d_1)] = 0 \\times P(H_1|x) + f \\times P(H_2|x) = f \\times P(H_2|x) = 20 \\times P(H_2|x) \\] In order to calculate the expected loss for the decision, that a patient does not have diabetes (\\(E[L(d_2)]\\)), we add the product of \\(loss_{Miss}\\) and the probability of \\(H_1\\) given our data and the the product of \\(loss_{Correct~Rejection}\\) and the probability of \\(H_2\\) given our data together. Since \\(loss_{Correct~Rejection} = 0\\), \\(E[L(d_2)]\\) equals the product of \\(loss_{Miss}\\) and the probability of \\(H_2\\) given our data. \\[ E[L(d_2)] = m \\times P(H_1|x) + 0 \\times P(H_2|x) = m \\times P(H_1|x) = 10 \\times P(H_1|x) \\] Note that the the probability of \\(H_1\\) given our data - \\(P(H_1|x)\\) - can be obtained by calculating the column mean of the posterior distribution implied by the respective model (see line 661 for model 1 and line 715 for model 2). Accordingly the probability of \\(H_2\\) given our data - \\(P(H_2|x)\\) - can be obtained by subtracting \\(P(H_1|x)\\) from one (see line 662 for model 1 and line 716 for model 2). Let us now calculate \\(E[L(d_1)]\\) and \\(E[L(d_2)]\\) based on both our models for every participant of the original study. 2.3.5.1 Model 1: Diabetes Diagnosis ~ Glucose Level + BMI diabetes.predictions.model1.1 &lt;- diabetes.predictions.model1.1 %&gt;% add_column(ELd1 = NA, .after = &quot;probability.neg.diab.diagnosis&quot;) diabetes.predictions.model1.1 &lt;- diabetes.predictions.model1.1 %&gt;% add_column(ELd2 = NA, .after = &quot;ELd1&quot;) diabetes.predictions.model1.1 &lt;- diabetes.predictions.model1.1 %&gt;% add_column(classification.decision = NA, .after = &quot;ELd2&quot;) for (i in 1:length(diabetes.predictions.model1.1$outcome)) { diabetes.predictions.model1.1$ELd1[i] &lt;- 20 * diabetes.predictions.model1.1$probability.neg.diab.diagnosis[i] } for (i in 1:length(diabetes.predictions.model1.1$outcome)) { diabetes.predictions.model1.1$ELd2[i] &lt;- 10 * diabetes.predictions.model1.1$probability.pos.diab.diagnosis[i] } diab.plot$model1.ELd1 &lt;- diabetes.predictions.model1.1$ELd1 diab.plot$model1.ELd2 &lt;- diabetes.predictions.model1.1$ELd2 model1.1.loss.plot &lt;- plot_ly(diab.plot, x = ~glucose, y = ~bmi, z = ~model1.ELd1, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Expected Loss for\\nDecision 1&quot;, marker = list(size = 3, color = &quot;#f4cccc&quot;)) model1.1.loss.plot &lt;- model1.1.loss.plot %&gt;% add_trace(diab.plot, x = ~glucose, y = ~bmi, z = ~model1.ELd2, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Expected Loss for\\nDecision 2&quot;, marker = list(size = 3, color = &quot;#e68d8d&quot;)) model1.1.loss.plot &lt;- model1.1.loss.plot %&gt;% layout(title = list(text = &quot;Model 1: Diabetes Diagnosis ~ Glucose Level + BMI&quot;, y = 0.95), scene = list(xaxis = list(title = &quot;Glucose Level [scaled]&quot;), yaxis = list(title = &quot;Body Mass Index [scaled]&quot;), zaxis = list(title = &quot;Expected Loss&quot;)), legend = list(y = 0.05)) model1.1.loss.plot 2.3.5.2 Model 2: Diabetes Diagnosis ~ Glucose Level + Age diabetes.predictions.model2.1 &lt;- diabetes.predictions.model2.1 %&gt;% add_column(ELd1 = NA, .after = &quot;probability.neg.diab.diagnosis&quot;) diabetes.predictions.model2.1 &lt;- diabetes.predictions.model2.1 %&gt;% add_column(ELd2 = NA, .after = &quot;ELd1&quot;) diabetes.predictions.model2.1 &lt;- diabetes.predictions.model2.1 %&gt;% add_column(classification.decision = NA, .after = &quot;ELd2&quot;) for (i in 1:length(diabetes.predictions.model2.1$outcome)) { diabetes.predictions.model2.1$ELd1[i] &lt;- 20 * diabetes.predictions.model2.1$probability.neg.diab.diagnosis[i] } for (i in 1:length(diabetes.predictions.model2.1$outcome)) { diabetes.predictions.model2.1$ELd2[i] &lt;- 10 * diabetes.predictions.model2.1$probability.pos.diab.diagnosis[i] } diab.plot$model2.ELd1 &lt;- diabetes.predictions.model2.1$ELd1 diab.plot$model2.ELd2 &lt;- diabetes.predictions.model2.1$ELd2 model2.1.loss.plot &lt;- plot_ly(diab.plot, x = ~glucose, y = ~age, z = ~model2.ELd1, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Expected Loss for\\nDecision 1&quot;, marker = list(size = 3, color = &quot;#C0D6E4&quot;)) model2.1.loss.plot &lt;- model2.1.loss.plot %&gt;% add_trace(diab.plot, x = ~glucose, y = ~age, z = ~model2.ELd2, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, name = &quot;Expected Loss for\\nDecision 2&quot;, marker = list(size = 3, color = &quot;#8ab3cd&quot;)) model2.1.loss.plot &lt;- model2.1.loss.plot %&gt;% layout(title = list(text = &quot;Model 2: Diabetes Diagnosis ~ Glucose Level + Age&quot;, y = 0.95), scene = list(xaxis = list(title = &quot;Glucose Level [scaled]&quot;), yaxis = list(title = &quot;Age [scaled]&quot;), zaxis = list(title = &quot;Expected Loss&quot;)), legend = list(y = 0.05)) model2.1.loss.plot 2.3.6 Making Decisions based on Expected Losses Now that we have calculated \\(E[L(d_1)]\\) and \\(E[L(d_2)]\\) based on both our models we can classify the participants in the study as either “diabetic” or “non-diabetic” by comparing \\(E[L(d_1)]\\) and \\(E[L(d_2)]\\): If \\(E[L(d_1)] &lt; E[L(d_2)]\\) we classify the participant as “diabetic”. If \\(E[L(d_1)] &gt; E[L(d_2)]\\) we classify the participant as “non-diabetic”. for (i in 1:length(diabetes.predictions.model1.1$outcome)) { if (diabetes.predictions.model1.1$ELd1[i] &lt; diabetes.predictions.model1.1$ELd2[i]) { diabetes.predictions.model1.1$classification.decision[i] &lt;- &quot;diabetic&quot; } else if (diabetes.predictions.model1.1$ELd1[i] &gt; diabetes.predictions.model1.1$ELd2[i]) { diabetes.predictions.model1.1$classification.decision[i] &lt;- &quot;non-diabetic&quot; } } ########### for (i in 1:length(diabetes.predictions.model2.1$outcome)) { if (diabetes.predictions.model2.1$ELd1[i] &lt; diabetes.predictions.model2.1$ELd2[i]) { diabetes.predictions.model2.1$classification.decision[i] &lt;- &quot;diabetic&quot; } else if (diabetes.predictions.model2.1$ELd1[i] &gt; diabetes.predictions.model2.1$ELd2[i]) { diabetes.predictions.model2.1$classification.decision[i] &lt;- &quot;non-diabetic&quot; } } 2.3.7 Look what we did! Next we inspect the results of the application of our loss functions by creating some confusion matrices and calculating the accuracy statistics. 2.3.7.1 Confusion Matrices - Cut-Off Value based on \\(E[L(d_1)]\\) and \\(E[L(d_2)]\\) model1.ELd.pred.pos.rec.pos &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.decision == &quot;diabetic&quot; &amp; diabetes.predictions.model1.1$outcome == &quot;1&quot;, ]) model1.ELd.pred.neg.rec.pos &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.decision == &quot;non-diabetic&quot; &amp; diabetes.predictions.model1.1$outcome == &quot;1&quot;, ]) model1.ELd.pred.pos.rec.neg &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.decision == &quot;diabetic&quot; &amp; diabetes.predictions.model1.1$outcome == &quot;0&quot;, ]) model1.ELd.pred.neg.rec.neg &lt;- nrow(diabetes.predictions.model1.1[diabetes.predictions.model1.1$classification.decision == &quot;non-diabetic&quot; &amp; diabetes.predictions.model1.1$outcome == &quot;0&quot;, ]) model1.ELd.hits &lt;- model1.ELd.pred.pos.rec.pos model1.ELd.misses &lt;- model1.ELd.pred.neg.rec.pos model1.ELd.false.alarms &lt;- model1.ELd.pred.pos.rec.neg model1.ELd.correct.rejections &lt;- model1.ELd.pred.neg.rec.neg ########### model2.ELd.pred.pos.rec.pos &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.decision == &quot;diabetic&quot; &amp; diabetes.predictions.model2.1$outcome == &quot;1&quot;, ]) model2.ELd.pred.neg.rec.pos &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.decision == &quot;non-diabetic&quot; &amp; diabetes.predictions.model2.1$outcome == &quot;1&quot;, ]) model2.ELd.pred.pos.rec.neg &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.decision == &quot;diabetic&quot; &amp; diabetes.predictions.model2.1$outcome == &quot;0&quot;, ]) model2.ELd.pred.neg.rec.neg &lt;- nrow(diabetes.predictions.model2.1[diabetes.predictions.model2.1$classification.decision == &quot;non-diabetic&quot; &amp; diabetes.predictions.model2.1$outcome == &quot;0&quot;, ]) model2.ELd.hits &lt;- model2.ELd.pred.pos.rec.pos model2.ELd.misses &lt;- model2.ELd.pred.neg.rec.pos model2.ELd.false.alarms &lt;- model2.ELd.pred.pos.rec.neg model2.ELd.correct.rejections &lt;- model2.ELd.pred.neg.rec.neg Model 1 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 48 Hits 16 False Alarms Predicted Diagnosis NEGATIVE 82 Misses 246 Correct Rejections Model 2 Recorded Diagnosis POSITIVE Recorded Diagnosis NEGATIVE Predicted Diagnosis POSITIVE 51 Hits 14 False Alarms Predicted Diagnosis NEGATIVE 79 Misses 248 Correct Rejections 2.3.7.2 Accuracy Statistics model1.ELd.acc &lt;- (model1.ELd.hits + model1.ELd.correct.rejections)/(model1.ELd.hits + model1.ELd.false.alarms + model1.ELd.misses + model1.ELd.correct.rejections) model1.ELd.sens &lt;- model1.ELd.hits/(model1.ELd.hits + model1.ELd.misses) model1.ELd.spec &lt;- model1.ELd.correct.rejections/(model1.ELd.false.alarms + model1.ELd.correct.rejections) model1.ELd.bacc &lt;- model1.ELd.sens * 0.5 + model1.ELd.spec * 0.5 ########### model2.ELd.acc &lt;- (model2.ELd.hits + model2.ELd.correct.rejections)/(model2.ELd.hits + model2.ELd.false.alarms + model2.ELd.misses + model2.ELd.correct.rejections) model2.ELd.sens &lt;- model2.ELd.hits/(model2.ELd.hits + model2.ELd.misses) model2.ELd.spec &lt;- model2.ELd.correct.rejections/(model2.ELd.false.alarms + model2.ELd.correct.rejections) model2.ELd.bacc &lt;- model2.ELd.sens * 0.5 + model2.ELd.spec * 0.5 Model 1 Cut-Off Value \\(p=0.5\\) Classification based on \\(E[L(d_1)]\\) &amp; \\(E[L(d_2)]\\) \\(\\Delta\\) Accuracy 0.7729592 0.75 -0.0229592 Sensitivity 0.5307692 0.3692308 -0.1615384 Specificity 0.8931298 0.9389313 0.0458015 Balanced Accuracy 0.7119495 0.654081 -0.0578685 Model 2 Cut-Off Value \\(p=0.5\\) Classification based on \\(E[L(d_1)]\\) &amp; \\(E[L(d_2)]\\) \\(\\Delta\\) Accuracy 0.7857143 0.7627551 -0.0229592 Sensitivity 0.5692308 0.3923077 -0.1769231 Specificity 0.8931298 0.9465649 0.0534351 Balanced Accuracy 0.7311803 0.6694363 -0.061744 Cut-Off Value \\(p=0.5\\) Model 1 Model 2 \\(\\Delta\\) Accuracy 0.7729592 0.7857143 0.0127551 Sensitivity 0.5307692 0.5692308 0.0384616 Specificity 0.8931298 0.8931298 0 Balanced Accuracy 0.7119495 0.7311803 0.0192308 Classification based on \\(E[L(d_1)]\\) &amp; \\(E[L(d_2)]\\) Model 1 Model 2 \\(\\Delta\\) Accuracy 0.75 0.7627551 0.0127551 Sensitivity 0.3692308 0.3923077 0.0230769 Specificity 0.9389313 0.9465649 0.0076336 Balanced Accuracy 0.654081 0.6694363 0.0153553 2.3.8 Conclusion One can clearly see, that we managed to increase the specificity of the first as well as the second model by applying our loss functions. When using the first model the specificity of our decision process increases by \\(0.0458015\\) when we base our classification decision on the comparison of \\(E[L(d_1)]\\) and \\(E[L(d_2)]\\) instead of using the usual cut-off value \\(p=0.5\\) for the probability of \\(H_1\\) and \\(H_2\\) given our data. When using the second model said increase in the specificity of our decision process is even higher (\\(0.0534351\\)). Although the application of our loss functions does not greatly diminish the accuracy of our decision process, when using either model, we do see a rather large decrease in sensitivity (model 1: \\(-0.1615384\\) - model 2: \\(-0.1769231\\)). Since the second model compared to the first model has the higher accuracy, sensitivity and specificity - as expected even when applying our loss functions to our decision process - I would recommend to “Living with Diabetes” to use the second model while applying our loss functions to their decision process. 2.3.9 Further Reading These are the resources I used to create the subchapter Bayesian Decision Theory: Bayes Factors for Forensic Decision Analyses with R by Bozza et al. (2022) An Introduction to Bayesian Thinking by Clyde et al. (2022) Introduction to Bayesian Inference for Psychology by Etz and Vandekerckhove (2018) Normative Theories of Decision Making Under Risk and Under Uncertainty by Fishburn (1988) Bayes rules: an introduction to Bayesian modeling by Johnson et al. (2022) The Bayesian Choice: From Decision-Theoretic Foundations to Computational Implementation by Robert (2007) Bayesian Logistic Regression with rstanarm by Vehtari at al. (2022) "],["unsupervised-learning.html", "Chapter 3 Unsupervised Learning 3.1 Non-Hierarchical Clustering R 3.2 Non-Hierarchical Clustering Python", " Chapter 3 Unsupervised Learning 3.1 Non-Hierarchical Clustering R 3.1.1 Import Dataset iris R iris &lt;- read.csv(&quot;Data/iris.dat&quot;, row.names=NULL) iris$TCategory &lt;- as.factor(iris$TCategory) iris$Category &lt;- as.factor(iris$Category) # Inspecting the imported dataset glimpse(iris) ## Rows: 150 ## Columns: 6 ## $ Sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6,… ## $ Sepal_width &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4,… ## $ Petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4,… ## $ Petal_width &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3,… ## $ Category &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ TCategory &lt;fct&gt; I.setosa, I.setosa, I.setosa, I.se… str(iris) ## &#39;data.frame&#39;: 150 obs. of 6 variables: ## $ Sepal_length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal_width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal_length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal_width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Category : Factor w/ 3 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ TCategory : Factor w/ 3 levels &quot;I.setosa&quot;,&quot;I.versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... describe(iris) ## vars n mean sd median trimmed mad min ## Sepal_length 1 150 5.84 0.83 5.80 5.81 1.04 4.3 ## Sepal_width 2 150 3.05 0.43 3.00 3.04 0.37 2.0 ## Petal_length 3 150 3.76 1.76 4.35 3.76 1.85 1.0 ## Petal_width 4 150 1.20 0.76 1.30 1.18 1.04 0.1 ## Category* 5 150 2.00 0.82 2.00 2.00 1.48 1.0 ## TCategory* 6 150 2.00 0.82 2.00 2.00 1.48 1.0 ## max range skew kurtosis se ## Sepal_length 7.9 3.6 0.31 -0.61 0.07 ## Sepal_width 4.4 2.4 0.33 0.20 0.04 ## Petal_length 6.9 5.9 -0.27 -1.42 0.14 ## Petal_width 2.5 2.4 -0.10 -1.36 0.06 ## Category* 3.0 2.0 0.00 -1.52 0.07 ## TCategory* 3.0 2.0 0.00 -1.52 0.07 3.1.2 Clustering Using a k-means Algorithm Using the R package mclust I have chosen to use a k-means clustering algorithm to separate the flowers into three clusters based on their sepal length and width as well as on their petal length and width. iris &lt;- read.csv(&quot;Data/iris.dat&quot;, row.names = NULL) iris_wo_cat &lt;- iris[, 1:4] set.seed(15) iris_clusters &lt;- iris_wo_cat %&gt;% kmeans(centers = 3) %&gt;% fitted(&quot;classes&quot;) %&gt;% as.character() iris &lt;- iris %&gt;% mutate(cluster = iris_clusters) This method was adapted from the method described in chapter 9.1.2 in the book Modern Data Science with R by Baumer et al. (2017). 3.1.3 Visualization of Results of Clustering R iris_c_plot_1 &lt;- plot_ly(data = iris, x = ~Category, y = ~Sepal_length, color = ~cluster, type = &quot;scatter&quot;, mode = &quot;markers&quot;) iris_c_plot_1 &lt;- iris_c_plot_1 %&gt;% layout(xaxis = list(title = &quot;Species&quot;, showticklabels = TRUE, ticktext = list(&quot;Iris Setosa&quot;, &quot;Iris Versicolor&quot;, &quot;Iris Virginica&quot;), tickvals = list(0, 1, 2), tickmode = &quot;array&quot;, zeroline = FALSE), yaxis = list(title = &quot;Sepal Length [cm]&quot;, showticklabels = TRUE, zeroline = FALSE), legend = list(title = list(text = &quot;&lt;b&gt; Cluster &lt;/b&gt;&quot;))) iris_c_plot_1 Figure 3.1: Categorization vs. Clustering - plotted against Sepal Length using *R* iris_c_plot_2 &lt;- plot_ly(data = iris, x = ~Category, y = ~Sepal_width, color = ~cluster, type = &quot;scatter&quot;, mode = &quot;markers&quot;, showlegend = FALSE) iris_c_plot_2 &lt;- iris_c_plot_2 %&gt;% layout(xaxis = list(title = &quot;Species&quot;, showticklabels = TRUE, ticktext = list(&quot;Iris Setosa&quot;, &quot;Iris Versicolor&quot;, &quot;Iris Virginica&quot;), tickvals = list(0, 1, 2), tickmode = &quot;array&quot;, zeroline = FALSE), yaxis = list(title = &quot;Sepal Width [cm]&quot;, showticklabels = TRUE, zeroline = FALSE)) iris_c_plot_2 Figure 3.2: Categorization vs. Clustering - plotted against Sepal Width using *R* iris_c_plot_3 &lt;- plot_ly(data = iris, x = ~Category, y = ~Petal_length, color = ~cluster, type = &quot;scatter&quot;, mode = &quot;markers&quot;, showlegend = FALSE) iris_c_plot_3 &lt;- iris_c_plot_3 %&gt;% layout(xaxis = list(title = &quot;Species&quot;, showticklabels = TRUE, ticktext = list(&quot;Iris Setosa&quot;, &quot;Iris Versicolor&quot;, &quot;Iris Virginica&quot;), tickvals = list(0, 1, 2), tickmode = &quot;array&quot;, zeroline = FALSE), yaxis = list(title = &quot;Petal Length [cm]&quot;, showticklabels = TRUE, zeroline = FALSE)) iris_c_plot_3 Figure 3.3: Categorization vs. Clustering - plotted against Petal Length using *R* iris_c_plot_4 &lt;- plot_ly(data = iris, x = ~Category, y = ~Petal_width, color = ~cluster, type = &quot;scatter&quot;, mode = &quot;markers&quot;, showlegend = FALSE) iris_c_plot_4 &lt;- iris_c_plot_4 %&gt;% layout(xaxis = list(title = &quot;Species&quot;, showticklabels = TRUE, ticktext = list(&quot;Iris Setosa&quot;, &quot;Iris Versicolor&quot;, &quot;Iris Virginica&quot;), tickvals = list(0, 1, 2), tickmode = &quot;array&quot;, zeroline = FALSE), yaxis = list(title = &quot;Petal Width [cm]&quot;, showticklabels = TRUE, zeroline = FALSE)) iris_c_plot_4 Figure 3.4: Categorization vs. Clustering - plotted against Petal Width using *R* 3.2 Non-Hierarchical Clustering Python 3.2.1 Import Dataset iris Python # Import dataset &#39;iris&#39; as a &#39;Pandas Dataframe&#39; iris_df= pd.read_csv(&#39;Data/iris.dat&#39;, header=0) # Import dataset &#39;iris&#39; as a &#39;NumPy Array&#39; iris_arr= pd.read_csv(&#39;Data/iris.dat&#39;, header=0).values # Defining a function that checks whether the dataset is a &#39;Pandas Dataframe&#39; # or a &#39;NumPy Array&#39; and prints the structure of said dataset. def data_structure(dataset): if isinstance(dataset, pd.DataFrame): print(&quot;The dataset is a &#39;Pandas Dataframe&#39;&quot;, &quot;\\n&quot;, &quot;Number of dimensions of dataframe: &quot;, dataset.ndim, &quot;\\n&quot;, &quot;Shape of dataset: &quot;, dataset.shape, &quot;\\n&quot;, &quot;Size of dataset: &quot;, dataset.size ) elif isinstance(dataset, np.ndarray): print(&quot;The dataset is a &#39;NumPy Array&#39;&quot;, &quot;\\n&quot;, &quot;Number of dimensions of dataframe: &quot;,dataset.ndim, &quot;\\n&quot;, &quot;Shape of dataset: &quot;, dataset.shape, &quot;\\n&quot;, &quot;Size of dataset: &quot;, dataset.size ) else: raise ValueError(&quot;Please, choose either a &#39;Pandas Dataframe&#39; or a &#39;NumPy Array&#39;.&quot;) # Inspecting the imported datasets print(&quot;Inspecting type and structure of &#39;iris_df&#39;&quot;) ## Inspecting type and structure of &#39;iris_df&#39; data_structure(iris_df) ## The dataset is a &#39;Pandas Dataframe&#39; ## Number of dimensions of dataframe: 2 ## Shape of dataset: (150, 6) ## Size of dataset: 900 print(&quot;Inspecting type and structure of &#39;iris_arr&#39;&quot;) ## Inspecting type and structure of &#39;iris_arr&#39; data_structure(iris_arr) ## The dataset is a &#39;NumPy Array&#39; ## Number of dimensions of dataframe: 2 ## Shape of dataset: (150, 6) ## Size of dataset: 900 iris_df.head ## &lt;bound method NDFrame.head of Sepal_length Sepal_width ... Category TCategory ## 0 5.1 3.5 ... 0 I.setosa ## 1 4.9 3.0 ... 0 I.setosa ## 2 4.7 3.2 ... 0 I.setosa ## 3 4.6 3.1 ... 0 I.setosa ## 4 5.0 3.6 ... 0 I.setosa ## .. ... ... ... ... ... ## 145 6.7 3.0 ... 2 I.virginica ## 146 6.3 2.5 ... 2 I.virginica ## 147 6.5 3.0 ... 2 I.virginica ## 148 6.2 3.4 ... 2 I.virginica ## 149 5.9 3.0 ... 2 I.virginica ## ## [150 rows x 6 columns]&gt; 3.2.2 Preprocessing of Data All the numerical features, which the machine learning algorithm should consider in the process of clustering, were measured in the same unit (cm). Due to that fact it is not strictly necessary to conduct feature scaling during the preprocessing of the data. Nevertheless I chose to standardize the data, since I am trying to teach myself the best-practice approach to using machine learning algorithms. More information on preprocessing data can be found here. # Choosing the data used for the clustering iris_ml = iris_arr[:, :4].copy() # Standardization scaler = StandardScaler() iris_ml_std = scaler.fit_transform(iris_ml) # Inspecting the data used for clustering data_structure(iris_ml_std) ## The dataset is a &#39;NumPy Array&#39; ## Number of dimensions of dataframe: 2 ## Shape of dataset: (150, 4) ## Size of dataset: 600 iris_ml_std[:5, :] ## array([[-0.90068117, 1.03205722, -1.3412724 , -1.31297673], ## [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673], ## [-1.38535265, 0.33784833, -1.39813811, -1.31297673], ## [-1.50652052, 0.10644536, -1.2844067 , -1.31297673], ## [-1.02184904, 1.26346019, -1.3412724 , -1.31297673]]) 3.2.3 Clustering Using a k-means Algorithm In order to be able to compare workflows I searched for a clustering method in Python, which is similar to the one I adapted from Baumer et al. (2017). During my search I learned a great deal more about the k-means algorithm: The the conventional k-means algorithm is surprisingly simple and requires only a few simple steps. During the first step the algorithm randomly chooses k centroids, while k being equal to the number of clusters one chooses and centroids being data points representing the center of a cluster. The second step is actually a two-step processes called expectation-maximization, which is repeated until the positions of the centroids do not change anymore. First, during the expectation step of the second step, each data point is assigned to its nearest centroid. Then, during the maximization step of the second step, the mean of all data points is calculated for each cluster and a new centroid is set accordingly. Interestingly enough the quality of the cluster assignments is determined by computing the sum of the squared Euclidean distances of each data point to its closest centroid (sum of the squared error). Since the goal is to try to maximize the quality of the cluster assignments, the algorithm tries to minimize the error. Simple, but effective and not unlike what we are doing, when conducting a regression analysis. Below you can see what a conventional k-means algorithm looks like: 1: Specify the number k clusters to assign. 2: Randomly initialize k centroids. 3: repeat 4: – expectation: Assign each data point to its closest centroid. 5: – maximization: Compute the new centroid (mean) of each cluster. 6: until The centroid positions do not change. During my research I have come across the Python module scikit-learn and chose to use said module to replicate the clustering method adapted from Baumer et al. (2017) (see above) using Python. kmeans = KMeans(init=&quot;random&quot;, n_clusters=3, n_init=10, max_iter=300, random_state=15) kmeans.fit(iris_ml_std) #sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}KMeans(init=&#x27;random&#x27;, n_clusters=3, n_init=10, random_state=15)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(init=&#x27;random&#x27;, n_clusters=3, n_init=10, random_state=15) cl_kmeans_lowest_SSE = kmeans.inertia_ cl_kmeans_centers = kmeans.cluster_centers_ cl_kmeans_req_it = kmeans.n_iter_ print(&quot;The lowest SSE value: &quot;, cl_kmeans_lowest_SSE) ## The lowest SSE value: 141.15417813388655 print(&quot;Final locations of the centroids: &quot;, &quot;\\n&quot;, cl_kmeans_centers) ## Final locations of the centroids: ## [[ 1.16743407 0.15377779 1.00314548 1.02963256] ## [-1.01457897 0.84230679 -1.30487835 -1.25512862] ## [-0.01139555 -0.87288504 0.37688422 0.31165355]] print(&quot;The number of iterations required to converge: &quot;, cl_kmeans_req_it) ## The number of iterations required to converge: 4 cl_labels = kmeans.labels_ cl_labels = cl_labels.reshape(-1, 1) # Add cluster assignments to &#39;iris_arr&#39; iris_arr_cl = iris_arr.copy() iris_arr_cl = np.concatenate((iris_arr_cl, cl_labels), axis=1) # Add cluster assignments to &#39;iris_df&#39; iris_df_cl = iris_df.copy() cl_labels_str = cl_labels.copy() cl_labels_str = cl_labels_str.astype(str) iris_df_cl[&quot;Cluster&quot;] = cl_labels_str The method which I used to conduct the k-means clustering in Python I adapted from an online tutorial by Arvai (2022). 3.2.4 Visualization of Results of Clustering Python iris_c_plot_1_py = px.scatter( iris_df_cl, x=&quot;TCategory&quot;, y=&quot;Sepal_length&quot;, color=&quot;Cluster&quot;, labels=dict( TCategory=&quot;Species&quot;, Sepal_length=&quot;Sepal Length (cm)&quot;), template=&quot;plotly_white&quot;) iris_c_plot_1_py.update_layout( xaxis= dict( tickmode=&quot;array&quot;, tickvals=[0,1,2], ticktext=[&quot;Iris Setosa&quot;,&quot;Iris Versicolor&quot;,&quot;Iris Virginica&quot;])) Figure 3.5: Categorization vs. Clustering - plotted against Sepal Length using *Python* iris_c_plot_2_py = px.scatter( iris_df_cl, x=&quot;TCategory&quot;, y=&quot;Sepal_width&quot;, color=&quot;Cluster&quot;, labels=dict( TCategory=&quot;Species&quot;, Sepal_width=&quot;Sepal Width (cm)&quot;), template=&quot;plotly_white&quot;) iris_c_plot_2_py.update_layout( xaxis= dict( tickmode=&quot;array&quot;, tickvals=[0,1,2], ticktext=[&quot;Iris Setosa&quot;,&quot;Iris Versicolor&quot;,&quot;Iris Virginica&quot;])) Figure 3.6: Categorization vs. Clustering - plotted against Sepal Width using *Python* iris_c_plot_3_py = px.scatter( iris_df_cl, x=&quot;TCategory&quot;, y=&quot;Petal_length&quot;, color=&quot;Cluster&quot;, labels=dict( TCategory=&quot;Species&quot;, Petal_length=&quot;Petal Length (cm)&quot;), template=&quot;plotly_white&quot;) iris_c_plot_3_py.update_layout( xaxis= dict( tickmode=&quot;array&quot;, tickvals=[0,1,2], ticktext=[&quot;Iris Setosa&quot;,&quot;Iris Versicolor&quot;,&quot;Iris Virginica&quot;])) Figure 3.7: Categorization vs. Clustering - plotted against Petal Length using *Python* iris_c_plot_4_py = px.scatter( iris_df_cl, x=&quot;TCategory&quot;, y=&quot;Petal_width&quot;, color=&quot;Cluster&quot;, labels=dict( TCategory=&quot;Species&quot;, Petal_width=&quot;Petal Width (cm)&quot;), template=&quot;plotly_white&quot;) iris_c_plot_4_py.update_layout( xaxis= dict( tickmode=&quot;array&quot;, tickvals=[0,1,2], ticktext=[&quot;Iris Setosa&quot;,&quot;Iris Versicolor&quot;,&quot;Iris Virginica&quot;])) Figure 3.8: Categorization vs. Clustering - plotted against Petal Width using *Python* 3.2.5 Conclusion Figures one through four clearly show, that the method, which I adapated from Bauner et al. (2017) yields surprisingly good results, given the data the calculations are based on. Comparing the figures mentioned above with the figures five through eight, it becomes clear that the “Python method”, which I adapted from Arvai (2022), yields surprisingly good results as well. Nevertheless I find it import to note that the “Python method” and the “R method” yield slightly different results. Hence further inspection of said differences is necessary. "],["supervised-learning.html", "Chapter 4 Supervised Learning 4.1 Introduction to Decision Trees", " Chapter 4 Supervised Learning 4.1 Introduction to Decision Trees 4.1.1 What are Decision Trees? Decision trees are non-parametric supervised learning algorithms, that are used to predict the class or value of a specific target variable. Predictions are based on n simple decision rules which are inferred from the set of data, which was used to train the respective algorithm (Chauhan, 2022). Hastie et al. (2009) differentiate between to classes of decision trees: Regression trees and classification trees. The former is a class of decision tree algorithms, that are used when the target variable is continuous; accordingly algorithms of the latter class are used, when the target variable is categorical. To simplify matters this chapter shall focus on classification trees. In contrast to other decision algorithms decision trees are non-compensatory. Decision algorithms, such as random forests and regression, which are typically compensatory algorithms, are designed to use most, if not all, of the available cue information. The design of such algorithms is based on the premise, that the value of one cue (a.k.a. feature or predictor) could overturn the evidence given by another or several other cues. Non-compensatory algorithms on the hand, such as decision trees, use only a partial subset of the given cue information to reach a decision. This design is based on the premise, that the value or values of one or several cues cannot be outweighed by the values of any other cues. In short this means that decision trees deliberately ignore information. This design can actually offer significant practical and statistical advantages (Phillips et al., 2017a). 4.1.2 Basic Concepts of Decision Trees Classification trees are used to solve binary classification tasks. The goal of tasks of this class is the prediction of a binary criterion value (e.g. having heart disease vs. not having heart disease) for each of a set of individual cases (e.g. patients) based on each case’s values on a not necessarily specified range of cues (e.g. thallium scintigraphy results, chest pain type etc.) (Phillips et al., 2017a). These kinds of decision trees (as well as decision trees in general) can be applied as an ordered set of n simple conditional rules (A ⟹ B). These rules are applied sequentially (Phillips et al., 2017a). 4.1.3 A Short History of Decision Trees One of the first decision tree algorithms was actually invented to model human learning in psychology (Hunt et al., 1966). This algorithm forms the foundation for many popular decision tree algorithms such as the ID3 algorithm (Quinlan, 1986), the C4.5 algorithm (Quinlan, 2003) and the famous CART (Classification And Regression Trees) algorithm (Breiman, 1984). For further information I recommend reading the short but very informative article “Decision Trees” by de Ville (2013). 4.1.4 Basic Terminology of Decision Trees Before we dive in deeper in the inner workings of decision trees I would like to give a short overview of the basic terminology used in the context of decision trees. Formally a decision tree is comprised of the following elements (Chauhan, 2022; Phillips et al., 2017a; “What Is a Decision Tree,” n.d.): The Root Node … is the top node of a decision tree. has no incoming branches. represents the entire population or sample. A Decision Node … is a sub-node (i.e. not a root node), that splits into further sub-nodes. represents cue-based questions. represents a subset of the data. Branches … represent answers to cue-based questions. Parent nodes … are nodes, that split into sub-nodes. Child nodes … are the sub-nodes of parent nodes. Leaf or terminal nodes … do not split into further sub-nodes. represent decisions. A Sub-tree … is a sub-section of the entire tree. 4.1.5 An Example of Creating a Decision Tree with Python Below you see an example of a decision tree, which I created using a free software machine learning library for the Python programming language called scikit-learn. The algorithm used for the creation of the following decision tree is based on the CART algorithm (Breiman, 1984). py_iris = load_iris() X, y = py_iris.data, py_iris.target clf = tree.DecisionTreeClassifier() clf = clf.fit(X, y) tree.plot_tree(clf) Unfortunately “the scikit-learn implementation does not support categorical variables for now” (“Decision Trees,” n.d.). Luckily the are R packages that allow the construction of decision trees based on categorical data. An example would be the rpart package. 4.1.6 An Example of Creating a Decision Tree with R Below you see an example of a decision tree, which I created using the rpart package. The algorithm used for the creation of the following decision tree is based on the CART algorithm (Breiman, 1984). 4.1.6.1 Preprocessing of Data set.seed(678) path &lt;- &quot;https://raw.githubusercontent.com/guru99-edu/R-Programming/master/titanic_data.csv&quot; titanic &lt;- read.csv(path) shuffle_index &lt;- sample(1:nrow(titanic)) titanic &lt;- titanic[shuffle_index, ] preclean_titanic &lt;- titanic preclean_titanic$age &lt;- as.integer(preclean_titanic$age) ## Warning: NAs introduced by coercion preclean_titanic$fare &lt;- as.integer(preclean_titanic$fare) ## Warning: NAs introduced by coercion clean_titanic &lt;- preclean_titanic %&gt;% # drop variables select(-c(home.dest, cabin, name, x, ticket)) %&gt;% # convert to factor level mutate(pclass = factor(pclass, levels = c(1, 2, 3), labels = c(&quot;Upper&quot;, &quot;Middle&quot;, &quot;Lower&quot;)), survived = factor(survived, levels = c(0, 1), labels = c(&quot;No&quot;, &quot;Yes&quot;)), sex = factor(sex), embarked = factor(embarked)) %&gt;% na.omit() 4.1.6.2 Creating a Train and Test Dataset create_train_test &lt;- function(data, size = 0.8, train = TRUE) { n_row = nrow(data) total_row = size * n_row train_sample &lt;- 1:total_row if (train == TRUE) { return(data[train_sample, ]) } else { return(data[-train_sample, ]) } } data_train &lt;- create_train_test(clean_titanic, 0.8, train = TRUE) # Train dataset with 80% of original data data_test &lt;- create_train_test(clean_titanic, 0.8, train = FALSE) # test dataset with 20% of original data 4.1.6.3 Creating and Visualizing the Decision Tree fit &lt;- rpart(survived ~ ., data = data_train, method = &quot;class&quot;) rpart.plot(fit, extra = 106) 4.1.6.4 Prediction of Data predict_unseen &lt;- predict(fit, data_test, type = &quot;class&quot;) table_mat &lt;- table(data_test$survived, predict_unseen) table_mat ## predict_unseen ## No Yes ## No 105 11 ## Yes 34 59 4.1.7 Advantages and Disadvantages of Decision Trees One of the big advantages of decision trees is, that they are incredibly simple to understand, to interpret and to visualize. Furthermore they are generally able to handle both numerical and categorical data. Another advantage is, that they can not only solve classification tasks, but regression tasks as well. Besides that they can even handle multi-output problems (problems where several outputs need to be predicted). Unfortunately, like any other algorithms or statistical methods, decision tree algorithms do have several disadvantages as well. The main and most important disadvantage of decision trees though is the problem of overfitting. As I have explained before decision tree algorithms are non-compensatory algorithms, i.e. they ignore data (see above). This does not mean though, that they are always simple. Quite the opposite in fact. Without the appropriate necessary restrictions decision trees can become highly complex networks of questions containing dozens or - depending on the respective dataset - even hundreds of dozens of nodes. Although such complex decision trees usually describe the data, which they were trained with, very well, they tend to be exceptionally bad at predicting data. Fortunately the problem of overfitting can be overcome by carefully pruning - i.e. trimming off certain branches of the decision tree - without decreasing the overall accuracy of the decision tree algorithm. One algorithm used to achieve this is the minimal cost-complexity pruning algorithm. For further information on the advantages and disadvantages of decision trees please read the respective article on the scikit-learn website (“Decision Trees,” n.d.). 4.1.8 Fast-and-Frugal Trees Another solution for the problem of overfitting is the usage of more restrictive forms of decision tree algorithms. One of the most restrictive forms of a decision tree is a fast-and-frugal tree (Phillips et al., 2017a). Based on the research by Gigerenzer and colleagues on the topic of heuristics Phillips, Neth (University of Constance), Woike and Gaissmaier (University of Constance) (2017a) build the R package FFTrees, that allows users to easily create, visualize, and evaluate fast-and-frugal trees. Furthermore the package introduces a very handy new class of algorithms for constructing fast-and-frugal trees. 4.1.9 Creating a FFT with FFTrees # Step 1: Create FFTs from training data and test on # testing data heart heart.fft &lt;- FFTrees(formula = diagnosis ~ ., data = heart.train, data.test = heart.test, main = &quot;Heart Disease&quot;, decision.labels = c(&quot;Low-Risk&quot;, &quot;High-Risk&quot;)) # Step 2: Inspect and summarize FFTs # Print statistics of the final FFT heart.fft ## Heart Disease ## FFTrees ## - Trees: 7 fast-and-frugal trees predicting diagnosis ## - Outcome costs: [hi = 0, mi = 1, fa = 1, cr = 0] ## ## FFT #1: Definition ## [1] If thal = {rd,fd}, decide High-Risk. ## [2] If cp != {a}, decide Low-Risk. ## [3] If ca &gt; 0, decide High-Risk, otherwise, decide Low-Risk. ## ## FFT #1: Training Accuracy ## Training data: N = 150, Pos (+) = 66 (44%) ## ## | | True + | True - | Totals: ## |----------|--------|--------| ## | Decide + | hi 54 | fa 18 | 72 ## | Decide - | mi 12 | cr 66 | 78 ## |----------|--------|--------| ## Totals: 66 84 N = 150 ## ## acc = 80.0% ppv = 75.0% npv = 84.6% ## bacc = 80.2% sens = 81.8% spec = 78.6% ## ## FFT #1: Training Speed, Frugality, and Cost ## mcu = 1.74, pci = 0.87, E(cost) = 0.200 # Print a verbal description of the final FFT inwords(heart.fft) ## [1] &quot;If thal = {rd,fd}, decide High-Risk.&quot; ## [2] &quot;If cp != {a}, decide Low-Risk.&quot; ## [3] &quot;If ca &gt; 0, decide High-Risk, otherwise, decide Low-Risk.&quot; # Print statistics of all FFTs summary(heart.fft) ## Heart Disease ## ## FFTrees ## - Trees: 7 fast-and-frugal trees predicting diagnosis ## - Parameters: algorithm = &#39;ifan&#39;, goal = &#39;bacc&#39;, goal.chase = &#39;bacc&#39;, ## sens.w = 0.5, max.levels = 4 ## ## ## Table: (\\#tab:fft)Tree definitions ## ## | tree| nodes|classes |cues |directions |thresholds |exits | ## |----:|-----:|:-------|:----------------|:----------|:-------------------|:---------| ## | 1| 3|c;c;n |thal;cp;ca |=;=;&gt; |rd,fd;a;0 |1;0;0.5 | ## | 2| 4|c;c;n;c |thal;cp;ca;slope |=;=;&gt;;= |rd,fd;a;0;flat,down |1;0;1;0.5 | ## | 3| 3|c;c;n |thal;cp;ca |=;=;&gt; |rd,fd;a;0 |0;1;0.5 | ## | 4| 4|c;c;n;c |thal;cp;ca;slope |=;=;&gt;;= |rd,fd;a;0;flat,down |1;1;0;0.5 | ## | 5| 3|c;c;n |thal;cp;ca |=;=;&gt; |rd,fd;a;0 |0;0;0.5 | ## | 6| 4|c;c;n;c |thal;cp;ca;slope |=;=;&gt;;= |rd,fd;a;0;flat,down |0;0;0;0.5 | ## | 7| 4|c;c;n;c |thal;cp;ca;slope |=;=;&gt;;= |rd,fd;a;0;flat,down |1;1;1;0.5 | ## ## ## Table: (\\#tab:fft)Tree statistics on training data ## ## | tree| n| hi| fa| mi| cr| sens| spec| far| ppv| npv| acc| bacc| wacc| cost_decisions| cost_cues| cost| pci| mcu| ## |----:|---:|--:|--:|--:|--:|----:|----:|----:|----:|----:|----:|----:|----:|--------------:|---------:|----:|----:|----:| ## | 1| 150| 54| 18| 12| 66| 0.82| 0.79| 0.21| 0.75| 0.85| 0.80| 0.80| 0.80| 0.20| 0| 0.20| 0.87| 1.74| ## | 2| 150| 57| 22| 9| 62| 0.86| 0.74| 0.26| 0.72| 0.87| 0.79| 0.80| 0.80| 0.21| 0| 0.21| 0.86| 1.84| ## | 3| 150| 44| 7| 22| 77| 0.67| 0.92| 0.08| 0.86| 0.78| 0.81| 0.79| 0.79| 0.19| 0| 0.19| 0.88| 1.56| ## | 4| 150| 60| 31| 6| 53| 0.91| 0.63| 0.37| 0.66| 0.90| 0.75| 0.77| 0.77| 0.25| 0| 0.25| 0.84| 2.12| ## | 5| 150| 28| 2| 38| 82| 0.42| 0.98| 0.02| 0.93| 0.68| 0.73| 0.70| 0.70| 0.27| 0| 0.27| 0.87| 1.70| ## | 6| 150| 21| 1| 45| 83| 0.32| 0.99| 0.01| 0.95| 0.65| 0.69| 0.65| 0.65| 0.31| 0| 0.31| 0.85| 1.90| ## | 7| 150| 64| 56| 2| 28| 0.97| 0.33| 0.67| 0.53| 0.93| 0.61| 0.65| 0.65| 0.39| 0| 0.39| 0.82| 2.30| ## ## ## Table: (\\#tab:fft)Tree statistics on test data ## ## | tree| n| hi| fa| mi| cr| sens| spec| far| ppv| npv| acc| bacc| wacc| cost_decisions| cost_cues| cost| pci| mcu| ## |----:|---:|--:|--:|--:|--:|----:|----:|----:|----:|----:|----:|----:|----:|--------------:|---------:|----:|----:|----:| ## | 1| 153| 64| 19| 9| 61| 0.88| 0.76| 0.24| 0.77| 0.87| 0.82| 0.82| 0.82| 0.18| 0| 0.18| 0.87| 1.73| ## | 2| 153| 67| 26| 6| 54| 0.92| 0.68| 0.32| 0.72| 0.90| 0.79| 0.80| 0.80| 0.21| 0| 0.21| 0.86| 1.85| ## | 3| 153| 49| 8| 24| 72| 0.67| 0.90| 0.10| 0.86| 0.75| 0.79| 0.79| 0.79| 0.21| 0| 0.21| 0.87| 1.63| ## | 4| 153| 69| 36| 4| 44| 0.95| 0.55| 0.45| 0.66| 0.92| 0.74| 0.75| 0.75| 0.26| 0| 0.26| 0.85| 1.95| ## | 5| 153| 28| 0| 45| 80| 0.38| 1.00| 0.00| 1.00| 0.64| 0.71| 0.69| 0.69| 0.29| 0| 0.29| 0.86| 1.78| ## | 6| 153| 22| 0| 51| 80| 0.30| 1.00| 0.00| 1.00| 0.61| 0.67| 0.65| 0.65| 0.33| 0| 0.33| 0.85| 1.97| ## | 7| 153| 72| 56| 1| 24| 0.99| 0.30| 0.70| 0.56| 0.96| 0.63| 0.64| 0.64| 0.37| 0| 0.37| 0.84| 2.11| # Step 4: Visualize the final FFT and performance # results # a) plot final FFT applied to test data: plot(heart.fft, data = &quot;test&quot;) # b) plot individual cue accuracies in ROC space: plot(heart.fft, what = &quot;cues&quot;) ## Using cue training statistics of object x: ## Cue accuracies ranked by bacc 4.1.10 Conclusion Decision tree algorithms are incredibly versatile and can be used in a number of contexts for wide range of problems. Due to their simplicity they are easy to understand, to interpret and to visualize. As well as any other algorithms they do have certain libations of course. Thanks to the work for example of scientists like Phillips et al. (2017a), many of these limitations can be overcome though. Fast-and-frugal trees especially have an amazing potential in a number of fields. Thus I recommend everyone to familiarize themselves with the usage of decision trees and to take a stroll though this algorithmic jungle. "],["references.html", "References Software Bibliography", " References Software R and RStudio cite_r_rstudio(cat_output = TRUE, write_bib_file = FALSE) ## -------------------------------------------------- ## R Version: 4.2.1 (2022-06-23) ## -------------------------------------------------- ## RStudio Version: Cherry Blossom - 2023.03.0+386 ## -------------------------------------------------- Posit team. (2023). RStudio: Integrated development environment for r. Posit Software, PBC. http://www.posit.co/ R Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/ R Packages Allaire, J., Xie, Y., McPherson, J., Luraschi, J., Ushey, K., Atkins, A., Wickham, H., Cheng, J., Chang, W., &amp; Iannone, R. (2022). Rmarkdown: Dynamic documents for r. https://CRAN.R-project.org/package=rmarkdown Almeida, A., Loy, A., &amp; Hofmann, H. (2018). ggplot2 compatible quantile-quantile plots in r. In The R Journal (No. 2; Vol. 10, pp. 248–261). https://doi.org/10.32614/RJ-2018-051 Almeida, A., Loy, A., &amp; Hofmann, H. (2021). Qqplotr: Quantile-quantile plot extensions for ggplot2. https://github.com/aloy/qqplotr Auguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra Bååth, R. (2013). Bayesian first aid. Tba. tba Bååth, R. (2023). BayesianFirstAid: Bayesian replacements for the most commonly used statistical tests in r. http://www.sumsar.net Bates, D., Mächler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01 Bates, D., Maechler, M., Bolker, B., &amp; Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/ Bates, D., Maechler, M., &amp; Jagan, M. (2022). Matrix: Sparse and dense matrix classes and methods. https://CRAN.R-project.org/package=Matrix Bolker, B., &amp; Robinson, D. (2022). Broom.mixed: Tidying methods for mixed models. https://github.com/bbolker/broom.mixed Brilleman, S., Crowther, M., Moreno-Betancur, M., Buros Novik, J., &amp; Wolfe, R. (2018). Joint longitudinal and time-to-event models via Stan. https://github.com/stan-dev/stancon_talks/ Bürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01 Bürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms. The R Journal, 10(1), 395–411. https://doi.org/10.32614/RJ-2018-017 Bürkner, P.-C. (2021). Bayesian item response modeling in R with brms and Stan. Journal of Statistical Software, 100(5), 1–54. https://doi.org/10.18637/jss.v100.i05 Bürkner, P.-C. (2023). Brms: Bayesian regression models using stan. https://CRAN.R-project.org/package=brms Csárdi, G., &amp; Chang, W. (2022). Processx: Execute and control system processes. https://CRAN.R-project.org/package=processx Csárdi, G., Hester, J., Wickham, H., Chang, W., Morgan, M., &amp; Tenenbaum, D. (2021). Remotes: R package installation from remote repositories, including GitHub. https://CRAN.R-project.org/package=remotes Dogucu, M., Johnson, A., &amp; Ott, M. (2021). Bayesrules: Datasets and supplemental functions from bayes rules! book. https://CRAN.R-project.org/package=bayesrules Dorai-Raj, S. (2022). Binom: Binomial confidence intervals for several parameterizations. https://CRAN.R-project.org/package=binom Eddelbuettel, D. (2013). Seamless R and C++ integration with Rcpp. Springer. https://doi.org/10.1007/978-1-4614-6868-4 Eddelbuettel, D., &amp; Balamuta, J. J. (2018). Extending extitR with extitC++: A Brief Introduction to extitRcpp. The American Statistician, 72(1), 28–36. https://doi.org/10.1080/00031305.2017.1375990 Eddelbuettel, D., Francois, R., Allaire, J., Ushey, K., Kou, Q., Russell, N., Ucar, I., Bates, D., &amp; Chambers, J. (2023). Rcpp: Seamless r and c++ integration. https://CRAN.R-project.org/package=Rcpp Eddelbuettel, D., &amp; François, R. (2011). Rcpp: Seamless R and C++ integration. Journal of Statistical Software, 40(8), 1–18. https://doi.org/10.18637/jss.v040.i08 Firke, S. (2021). Janitor: Simple tools for examining and cleaning dirty data. https://github.com/sfirke/janitor Fraley, C., Raftery, A. E., &amp; Scrucca, L. (2022). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/ Gabry, J., &amp; Goodrich, B. (2022). Rstanarm: Bayesian applied regression modeling via stan. https://CRAN.R-project.org/package=rstanarm Gabry, J., &amp; Mahr, T. (2022). Bayesplot: Plotting for bayesian models. https://mc-stan.org/bayesplot/ Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., &amp; Gelman, A. (2019). Visualization in bayesian workflow. J. R. Stat. Soc. A, 182, 389–402. https://doi.org/10.1111/rssa.12378 Goodrich, B., Gelman, A., Carpenter, B., Hoffman, M., Lee, D., Betancourt, M., Brubaker, M., Guo, J., Li, P., Riddell, A., Inacio, M., Morris, M., Arnold, J., Goedman, R., Lau, B., Trangucci, R., Gabry, J., Kucukelbir, A., Grant, R., … Gao, Y. (2020). StanHeaders: C++ header files for stan. https://mc-stan.org/ Guo, J., Gabry, J., Goodrich, B., &amp; Weber, S. (2023). Rstan: R interface to stan. https://CRAN.R-project.org/package=rstan Harding, T., Tusell, F., &amp; Schafer, J. L. (2022). Cat: Analysis and imputation of categorical-variable datasets with missing values. https://CRAN.R-project.org/package=cat Hester, J., &amp; Bryan, J. (2022). Glue: Interpreted string literals. https://CRAN.R-project.org/package=glue Iannone, R. (2022). DiagrammeR: Graph/network visualization. https://github.com/rich-iannone/DiagrammeR Kassambara, A. (2023a). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/ Kassambara, A. (2023b). Rstatix: Pipe-friendly framework for basic statistical tests. https://rpkgs.datanovia.com/rstatix/ Kay, M. (2022). Tidybayes: Tidy data and geoms for bayesian models. https://CRAN.R-project.org/package=tidybayes Kuhn, M. (2022). Caret: Classification and regression training. https://github.com/topepo/caret/ Lenth, R. V. (2023). Emmeans: Estimated marginal means, aka least-squares means. https://github.com/rvlenth/emmeans Lüdecke, D., Ben-Shachar, M. S., Patil, I., Waggoner, P., &amp; Makowski, D. (2021). performance: An R package for assessment, comparison and testing of statistical models. Journal of Open Source Software, 6(60), 3139. https://doi.org/10.21105/joss.03139 Lüdecke, D., Makowski, D., Ben-Shachar, M. S., Patil, I., Waggoner, P., &amp; Wiernik, B. M. (2022). Performance: Assessment of regression models performance. https://easystats.github.io/performance/ Mazerolle, M. J. (2023). AICcmodavg: Model selection and multimodel inference based on (q)AIC(c). https://CRAN.R-project.org/package=AICcmodavg McLean, M. W. (2014). Straightforward bibliography management in r using the RefManager package. https://arxiv.org/abs/1403.2036 McLean, M. W. (2017). RefManageR: Import and manage BibTeX and BibLaTeX references in r. The Journal of Open Source Software. https://doi.org/10.21105/joss.00338 McLean, M. W. (2022). RefManageR: Straightforward BibTeX and BibLaTeX bibliography management. https://github.com/ropensci/RefManageR/ Milborrow, S. (2022). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html Morey, R. D., &amp; Rouder, J. N. (2022). BayesFactor: Computation of bayes factors for common designs. https://richarddmorey.github.io/BayesFactor/ Müller, K., &amp; Wickham, H. (2023). Tibble: Simple data frames. https://CRAN.R-project.org/package=tibble Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017). FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. Judgment and Decision Making, 12(4), 344–368. https://CRAN.R-project.org/package=FFTrees Phillips, N., Neth, H., Woike, J., &amp; Gaissmaier, W. (2022). FFTrees: Generate, visualise, and evaluate fast-and-frugal decision trees. https://CRAN.R-project.org/package=FFTrees Plummer, M. (2022). Rjags: Bayesian graphical models using MCMC. https://mcmc-jags.sourceforge.io Plummer, M., Best, N., Cowles, K., &amp; Vines, K. (2006). CODA: Convergence diagnosis and output analysis for MCMC. R News, 6(1), 7–11. https://journal.r-project.org/archive/ Plummer, M., Best, N., Cowles, K., Vines, K., Sarkar, D., Bates, D., Almond, R., &amp; Magnusson, A. (2020). Coda: Output analysis and diagnostics for MCMC. https://CRAN.R-project.org/package=coda R Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/ Revelle, W. (2022). Psych: Procedures for psychological, psychometric, and personality research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf Robinson, D., Hayes, A., &amp; Couch, S. (2022). Broom: Convert statistical objects into tidy tibbles. https://CRAN.R-project.org/package=broom Sarkar, D. (2008). Lattice: Multivariate data visualization with r. Springer. http://lmdvr.r-forge.r-project.org Sarkar, D. (2021). Lattice: Trellis graphics for r. http://lattice.r-forge.r-project.org/ Scrucca, L., Fop, M., Murphy, T. B., &amp; Raftery, A. E. (2016). mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1), 289–317. https://doi.org/10.32614/RJ-2016-021 Sievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com Sievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., &amp; Despouy, P. (2022). Plotly: Create interactive web graphics via plotly.js. https://CRAN.R-project.org/package=plotly Singmann, H. (2023). Stanova: Bayesian models with categorical variables. Singmann, H., Bolker, B., Westfall, J., Aust, F., &amp; Ben-Shachar, M. S. (2022). Afex: Analysis of factorial experiments. https://CRAN.R-project.org/package=afex Therneau, T., &amp; Atkinson, B. (2022). Rpart: Recursive partitioning and regression trees. https://CRAN.R-project.org/package=rpart Ushey, K., Allaire, J., &amp; Tang, Y. (2022). Reticulate: Interface to python. https://CRAN.R-project.org/package=reticulate Wickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org Wickham, H. (2022a). Forcats: Tools for working with categorical variables (factors). https://CRAN.R-project.org/package=forcats Wickham, H. (2022b). Stringr: Simple, consistent wrappers for common string operations. https://CRAN.R-project.org/package=stringr Wickham, H. (2022c). Tidyverse: Easily install and load the tidyverse. https://CRAN.R-project.org/package=tidyverse Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 Wickham, H., Bryan, J., &amp; Barrett, M. (2022). Usethis: Automate package and project setup. https://CRAN.R-project.org/package=usethis Wickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., &amp; Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://CRAN.R-project.org/package=ggplot2 Wickham, H., François, R., Henry, L., &amp; Müller, K. (2022). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr Wickham, H., &amp; Henry, L. (2023). Purrr: Functional programming tools. https://CRAN.R-project.org/package=purrr Wickham, H., Hester, J., &amp; Bryan, J. (2022). Readr: Read rectangular text data. https://CRAN.R-project.org/package=readr Wickham, H., Hester, J., Chang, W., &amp; Bryan, J. (2022). Devtools: Tools to make developing r packages easier. https://CRAN.R-project.org/package=devtools Wickham, H., Vaughan, D., &amp; Girlich, M. (2023). Tidyr: Tidy messy data. https://CRAN.R-project.org/package=tidyr Xie, Y. (2014). Knitr: A comprehensive tool for reproducible research in R. In V. Stodden, F. Leisch, &amp; R. D. Peng (Eds.), Implementing reproducible computational research. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595 Xie, Y. (2015). Dynamic documents with R and knitr (2nd ed.). Chapman; Hall/CRC. https://yihui.org/knitr/ Xie, Y. (2016). Bookdown: Authoring books and technical documents with R markdown. Chapman; Hall/CRC. https://bookdown.org/yihui/bookdown Xie, Y. (2022a). Bookdown: Authoring books and technical documents with r markdown. Xie, Y. (2022b). Knitr: A general-purpose package for dynamic report generation in r. https://yihui.org/knitr/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R markdown: The definitive guide. Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown Xie, Y., Dervieux, C., &amp; Riederer, E. (2020). R markdown cookbook. Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook Python cite_python(cat_output = TRUE, write_bib_file = FALSE) ## ------------------------- ## Python Version: 3.11.2 ## ------------------------- van Rossum, G., &amp; de Boer, J. (1991). Interactively testing remote servers using the python programming language. CWI Quarterly, 4(4), 283–304. Python Packages Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Rı́o, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2 Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science &amp;Amp\\(\\mathsemicolon\\) Engineering, 9(3), 90–95. https://doi.org/10.1109/mcse.2007.55 Inc., P. T. (2015). Collaborative data science. Plotly Technologies Inc. https://plot.ly McKinney, W. (2010). Data structures for statistical computing in python. Proceedings of the Python in Science Conference. https://doi.org/10.25080/majora-92bf1922-00a Satopaa, V., Albrecht, J., Irwin, D., &amp; Raghavan, B. (2011, June). Finding a \"kneedle\" in a haystack: Detecting knee points in system behavior. 2011 31st International Conference on Distributed Computing Systems Workshops. https://doi.org/10.1109/icdcsw.2011.20 Scikit-learn: Machine learning in Python. (n.d.). Seabold, S., &amp; Perktold, J. (2010). Statsmodels: Econometric and statistical modeling with python. 9th Python in Science Conference. Virtanen, P., Gommers, R., Oliphant, T. E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., van der Walt, S. J., Brett, M., Wilson, J., Millman, K. J., Mayorov, N., Nelson, A. R. J., Jones, E., Kern, R., Larson, E., … and, Y. V.-B. (2020). SciPy 1.0: Fundamental algorithms for scientific computing in python. Nature Methods, 17(3), 261–272. https://doi.org/10.1038/s41592-019-0686-2 Waskom, M. (2021). Seaborn: Statistical data visualization. Journal of Open Source Software, 6(60), 3021. https://doi.org/10.21105/joss.03021 Bibliography Arvai, K. (2022). K-means clustering in python: A practical guide. In Real Python. Real Python. https://realpython.com/k-means-clustering-python/#how-to-perform-k-means-clustering-in-python Baumer, D. T., Benjamin S.and Kaplan, &amp; Horton, N. J. (2017). Modern data science with r. CRC Press. https://doi.org/10.1201/9781315113760 Bozza, S., Taroni, F., &amp; Biedermann, A. (2022). Bayes factors for forensic decision analyses with r (1st 2022.) [Book]. Springer International Publishing. https://doi.org/10.1007/978-3-031-09839-0 Breiman, L. (1984). Classification and regression trees. Wadsworth Internat. Group. Chauhan, N. S. (2022). Decision tree algorithm, explained. In KDnuggets. KDnuggets. https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html Clyde, M., Çetinkaya-Rundel, M., Rundel, C., Banks, D., Chai, C., &amp; Huang, L. (2022). An introduction to bayesian thinking [Web Book]. https://statswithr.github.io/book/ Decision trees. (n.d.). In scikit-learn. scikit-learn. Retrieved November 30, 2022, from https://scikit-learn.org/stable/modules/tree.html Etz, A., &amp; Vandekerckhove, J. (2018). Introduction to bayesian inference for psychology [Journal Article]. Psychonomic Bulletin &amp; Review, 25(1), 5–34. https://doi.org/10.3758/s13423-017-1262-3 Fishburn, P. C. (1988). Normative theories of decision making under risk and under uncertainty [Book Section]. In A. Tversky, D. E. Bell, &amp; H. Raiffa (Eds.), Decision making: Descriptive, normative, and prescriptive interactions (pp. 78–98). Cambridge University Press. https://doi.org/10.1017/CBO9780511598951.006 Hastie, T., Tibshirani, R., &amp; Friedman, J. H. (2009). The elements of statistical learning: Data mining, inference, and prediction (2. ed.). Springer. Hunt, E. B., Marin, J., &amp; Stone, P. J. (1966). Experiments in induction. Academic Pr. Johnson, A. A., Ott, M. Q., &amp; Dogucu, M. (2022). Bayes rules: An introduction to bayesian modeling [Book]. CRC Press Taylor &amp; Francis Group. https://go.exlibris.link/bsmRK8wq Jones, D. N., &amp; Paulhus, D. L. (2014). Introducing the short dark triad (SD3): A brief measure of dark personality traits. Assessment, 21(1), 28–41. https://doi.org/10.1177/1073191113514105 Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017). FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. Judgment and Decision Making, 12(4), 344–368. Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1(1), 81–106. https://doi.org/10.1007/BF00116251 Quinlan, J. R. (2003). C4.5: Programs for machine learning (5. [pr.]). Morgan Kaufmann. ritvikmath. (2020). Markov chains : Data science basics [YouTube Video]. In YouTube. https://www.youtube.com/watch?v=prZMpThbU3E ritvikmath. (2021a). Monte carlo methods : Data science basics [YouTube Video]. In YouTube. https://www.youtube.com/watch?v=EaR3C4e600k ritvikmath. (2021b). Markov chain monte carlo (MCMC) : Data science concepts [YouTube Video]. In YouTube. https://www.youtube.com/watch?v=yApmR-c_hKU Robert, C. P. (2007). The bayesian choice: From decision-theoretic foundations to computational implementation (2nd ed., p. 615) [Book]. Springer. https://doi.org/10.1007/0-387-71599-1 Vehtari, A., Gabry, J., &amp; Goodrich, B. (2022). Bayesian logistic regression with rstanarm [Web Page]. Aki Vehtari: Model Selection. https://avehtari.github.io/modelselection/diabetes.html Ville, B. de. (2013). WIREs Computational Statistics, 5(6), 448–455. https://doi.org/https://doi.org/10.1002/wics.1278 What is a decision tree. (n.d.). In IBM. IBM. Retrieved November 30, 2022, from https://www.ibm.com/topics/decision-trees Winter, B., &amp; Bürkner, P.-C. (2021). Poisson regression for linguists: A tutorial introduction to modelling count data with brms. Language and Linguistics Compass, 15(11), e12439. https://doi.org/https://doi.org/10.1111/lnc3.12439 Xie, Y., Dervieux, C., &amp; Riederer, E. (2022). R markdown cookbook. Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
