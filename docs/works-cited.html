<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Works Cited | Advanced Data Analysis in R and Python</title>
  <meta name="description" content="Works Cited | Advanced Data Analysis in R and Python" />
  <meta name="generator" content="bookdown 0.30.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Works Cited | Advanced Data Analysis in R and Python" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="hco-consulting/data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Works Cited | Advanced Data Analysis in R and Python" />
  
  
  

<meta name="author" content="Hamilkar Constantin Oueslati" />


<<<<<<< Updated upstream
<meta name="date" content="2022-12-01" />
=======
<meta name="date" content="2023-03-28" />
>>>>>>> Stashed changes

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="supervised-learning.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Data Analysis in R and Python</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contact-the-author"><i class="fa fa-check"></i>Contact the Author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prerequisites.html"><a href="prerequisites.html#load-r-packages"><i class="fa fa-check"></i><b>1.1</b> Load R Packages</a></li>
<li class="chapter" data-level="1.2" data-path="prerequisites.html"><a href="prerequisites.html#load-python-version-3.11.2"><i class="fa fa-check"></i><b>1.2</b> Load Python Version 3.11.2</a></li>
<li class="chapter" data-level="1.3" data-path="prerequisites.html"><a href="prerequisites.html#import-python-modules"><i class="fa fa-check"></i><b>1.3</b> Import Python Modules</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>2</b> Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-basics"><i class="fa fa-check"></i><b>2.1</b> Bayesian Basics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-binomial-test"><i class="fa fa-check"></i><b>2.1.1</b> Binomial Test</a></li>
<li class="chapter" data-level="2.1.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-t-test"><i class="fa fa-check"></i><b>2.1.2</b> Independent t-Test</a></li>
<li class="chapter" data-level="2.1.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-anova"><i class="fa fa-check"></i><b>2.1.3</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="2.1.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-regression"><i class="fa fa-check"></i><b>2.1.4</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#mcmc"><i class="fa fa-check"></i><b>2.2</b> Markov Chain Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#mcmc-basics"><i class="fa fa-check"></i><b>2.2.1</b> Understanding the Basics</a></li>
<li class="chapter" data-level="2.2.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#mcmc-irl"><i class="fa fa-check"></i><b>2.2.2</b> Real World Application</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt"><i class="fa fa-check"></i><b>2.3</b> Bayesian Decision Theory</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem"><i class="fa fa-check"></i><b>2.3.1</b> The Problem at Hand</a></li>
<li class="chapter" data-level="2.3.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem-mselection"><i class="fa fa-check"></i><b>2.3.2</b> Model Selection based on Accuracy Statistics</a></li>
<li class="chapter" data-level="2.3.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-WhatIsBDT"><i class="fa fa-check"></i><b>2.3.3</b> What is Bayesian Decision Theory?</a></li>
<li class="chapter" data-level="2.3.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem-AppL"><i class="fa fa-check"></i><b>2.3.4</b> Creating the Appropriate Loss Functions</a></li>
<li class="chapter" data-level="2.3.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem-LCalc"><i class="fa fa-check"></i><b>2.3.5</b> Calculating the Expected Losses for <span class="math inline">\(d_1\)</span> and <span class="math inline">\(d_2\)</span></a></li>
<li class="chapter" data-level="2.3.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#making-decisions-based-on-expected-losses"><i class="fa fa-check"></i><b>2.3.6</b> Making Decisions based on Expected Losses</a></li>
<li class="chapter" data-level="2.3.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem-res"><i class="fa fa-check"></i><b>2.3.7</b> Look what we did!</a></li>
<li class="chapter" data-level="2.3.8" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bdt-problem-conclusion"><i class="fa fa-check"></i><b>2.3.8</b> Conclusion</a></li>
<li class="chapter" data-level="2.3.9" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#further-reading"><i class="fa fa-check"></i><b>2.3.9</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>3</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#non-hierarchical-clustering-r"><i class="fa fa-check"></i><b>3.1</b> Non-Hierarchical Clustering <em>R</em></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#import-dataset-iris-r"><i class="fa fa-check"></i><b>3.1.1</b> Import Dataset <code>iris</code> <em>R</em></a></li>
<li class="chapter" data-level="3.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-k-means-algorithm"><i class="fa fa-check"></i><b>3.1.2</b> Clustering Using a <em>k</em>-means Algorithm</a></li>
<li class="chapter" data-level="3.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#visualization-results-clustering-r"><i class="fa fa-check"></i><b>3.1.3</b> Visualization of Results of Clustering <em>R</em></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#non-hierarchical-clustering-python"><i class="fa fa-check"></i><b>3.2</b> Non-Hierarchical Clustering <em>Python</em></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#import-dataset-iris-python"><i class="fa fa-check"></i><b>3.2.1</b> Import Dataset <code>iris</code> <em>Python</em></a></li>
<li class="chapter" data-level="3.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#preprocessing-of-data"><i class="fa fa-check"></i><b>3.2.2</b> Preprocessing of Data</a></li>
<li class="chapter" data-level="3.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-using-a-k-means-algorithm"><i class="fa fa-check"></i><b>3.2.3</b> Clustering Using a <em>k</em>-means Algorithm</a></li>
<li class="chapter" data-level="3.2.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#visualization-results-clustering-python"><i class="fa fa-check"></i><b>3.2.4</b> Visualization of Results of Clustering <em>Python</em></a></li>
<li class="chapter" data-level="3.2.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#conclusion-k-means"><i class="fa fa-check"></i><b>3.2.5</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>4</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="supervised-learning.html"><a href="supervised-learning.html#into-decision-trees"><i class="fa fa-check"></i><b>4.1</b> Introduction to Decision Trees</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="supervised-learning.html"><a href="supervised-learning.html#what-dt"><i class="fa fa-check"></i><b>4.1.1</b> What are Decision Trees?</a></li>
<li class="chapter" data-level="4.1.2" data-path="supervised-learning.html"><a href="supervised-learning.html#concept-dt"><i class="fa fa-check"></i><b>4.1.2</b> Basic Concepts of Decision Trees</a></li>
<li class="chapter" data-level="4.1.3" data-path="supervised-learning.html"><a href="supervised-learning.html#history-dt"><i class="fa fa-check"></i><b>4.1.3</b> A Short History of Decision Trees</a></li>
<li class="chapter" data-level="4.1.4" data-path="supervised-learning.html"><a href="supervised-learning.html#terminology-dt"><i class="fa fa-check"></i><b>4.1.4</b> Basic Terminology of Decision Trees</a></li>
<li class="chapter" data-level="4.1.5" data-path="supervised-learning.html"><a href="supervised-learning.html#eg-dt-python"><i class="fa fa-check"></i><b>4.1.5</b> An Example of Creating a Decision Tree with <em>Python</em></a></li>
<li class="chapter" data-level="4.1.6" data-path="supervised-learning.html"><a href="supervised-learning.html#eg-dt-r"><i class="fa fa-check"></i><b>4.1.6</b> An Example of Creating a Decision Tree with <em>R</em></a></li>
<li class="chapter" data-level="4.1.7" data-path="supervised-learning.html"><a href="supervised-learning.html#adv-disadv-dt"><i class="fa fa-check"></i><b>4.1.7</b> Advantages and Disadvantages of Decision Trees</a></li>
<li class="chapter" data-level="4.1.8" data-path="supervised-learning.html"><a href="supervised-learning.html#fft"><i class="fa fa-check"></i><b>4.1.8</b> Fast-and-Frugal Trees</a></li>
<li class="chapter" data-level="4.1.9" data-path="supervised-learning.html"><a href="supervised-learning.html#fft-creation"><i class="fa fa-check"></i><b>4.1.9</b> Creating a FFT with <code>FFTrees</code></a></li>
<li class="chapter" data-level="4.1.10" data-path="supervised-learning.html"><a href="supervised-learning.html#dt-conclusion"><i class="fa fa-check"></i><b>4.1.10</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="works-cited.html"><a href="works-cited.html"><i class="fa fa-check"></i>Works Cited</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Data Analysis in R and Python</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="works-cited" class="section level1 unnumbered hasAnchor">
<h1>Works Cited<a href="works-cited.html#works-cited" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Arvai2022" class="csl-entry">
Arvai, K. (2022). K-means clustering in python: A practical guide. In <em>Real Python</em>. Real Python. <a href="https://realpython.com/k-means-clustering-python/#how-to-perform-k-means-clustering-in-python">https://realpython.com/k-means-clustering-python/#how-to-perform-k-means-clustering-in-python</a>
</div>
<div id="ref-Baumer2017" class="csl-entry">
Baumer, D. T., Benjamin S.and Kaplan, &amp; Horton, N. J. (2017). <em>Modern data science with r</em>. CRC Press. <a href="https://doi.org/10.1201/9781315113760">https://doi.org/10.1201/9781315113760</a>
</div>
<div id="ref-Bozza2022" class="csl-entry">
Bozza, S., Taroni, F., &amp; Biedermann, A. (2022). <em>Bayes factors for forensic decision analyses with r</em> (1st 2022.) [Book]. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-09839-0">https://doi.org/10.1007/978-3-031-09839-0</a>
</div>
<div id="ref-Breiman1984" class="csl-entry">
Breiman, L. (1984). <em>Classification and regression trees</em>. Wadsworth Internat. Group.
</div>
<div id="ref-KDChauhan2022" class="csl-entry">
Chauhan, N. S. (2022). Decision tree algorithm, explained. In <em>KDnuggets</em>. KDnuggets. <a href="https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html">https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html</a>
</div>
<div id="ref-Clyde2022" class="csl-entry">
Clyde, M., Çetinkaya-Rundel, M., Rundel, C., Banks, D., Chai, C., &amp; Huang, L. (2022). <em>An introduction to bayesian thinking</em> [Web Book]. <a href="https://statswithr.github.io/book/">https://statswithr.github.io/book/</a>
</div>
<div id="ref-scikitDT" class="csl-entry">
Decision trees. (n.d.). In <em>scikit-learn</em>. scikit-learn. Retrieved November 30, 2022, from <a href="https://scikit-learn.org/stable/modules/tree.html">https://scikit-learn.org/stable/modules/tree.html</a>
</div>
<div id="ref-Etz2018" class="csl-entry">
Etz, A., &amp; Vandekerckhove, J. (2018). Introduction to bayesian inference for psychology [Journal Article]. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 5–34. <a href="https://doi.org/10.3758/s13423-017-1262-3">https://doi.org/10.3758/s13423-017-1262-3</a>
</div>
<div id="ref-Fishburn1988" class="csl-entry">
Fishburn, P. C. (1988). Normative theories of decision making under risk and under uncertainty [Book Section]. In A. Tversky, D. E. Bell, &amp; H. Raiffa (Eds.), <em>Decision making: Descriptive, normative, and prescriptive interactions</em> (pp. 78–98). Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511598951.006">https://doi.org/10.1017/CBO9780511598951.006</a>
</div>
<div id="ref-Hastie2009" class="csl-entry">
Hastie, T., Tibshirani, R., &amp; Friedman, J. H. (2009). <em>The elements of statistical learning: Data mining, inference, and prediction</em> (2. ed.). Springer.
</div>
<div id="ref-Hunt1966" class="csl-entry">
Hunt, E. B., Marin, J., &amp; Stone, P. J. (1966). <em>Experiments in induction</em>. Academic Pr.
</div>
<div id="ref-Johnson2022" class="csl-entry">
Johnson, A. A., Ott, M. Q., &amp; Dogucu, M. (2022). <em>Bayes rules: An introduction to bayesian modeling</em> [Book]. CRC Press Taylor &amp; Francis Group. <a href="https://go.exlibris.link/bsmRK8wq">https://go.exlibris.link/bsmRK8wq</a>
</div>
<div id="ref-SD32014" class="csl-entry">
Jones, D. N., &amp; Paulhus, D. L. (2014). Introducing the short dark triad (SD3): A brief measure of dark personality traits. <em>Assessment</em>, <em>21</em>(1), 28–41. <a href="https://doi.org/10.1177/1073191113514105">https://doi.org/10.1177/1073191113514105</a>
</div>
<div id="ref-Neth2017" class="csl-entry">
Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017). FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. <em>Judgment and Decision Making</em>, <em>12</em>(4), 344–368.
</div>
<div id="ref-Quinlan1986" class="csl-entry">
Quinlan, J. R. (1986). Induction of decision trees. <em>Machine Learning</em>, <em>1</em>(1), 81–106. <a href="https://doi.org/10.1007/BF00116251">https://doi.org/10.1007/BF00116251</a>
</div>
<div id="ref-Quinlan2003" class="csl-entry">
Quinlan, J. R. (2003). <em>C4.5: Programs for machine learning</em> (5. [pr.]). Morgan Kaufmann.
</div>
<div id="ref-MonteCarlo_Ritvik2021" class="csl-entry">
ritvikmath. (2021a). Monte carlo methods : Data science basics [YouTube Video]. In <em>YouTube</em>. <a href="https://www.youtube.com/watch?v=EaR3C4e600k">https://www.youtube.com/watch?v=EaR3C4e600k</a>
</div>
<div id="ref-MarkovChains_Ritvik2020" class="csl-entry">
ritvikmath. (2020). Markov chains : Data science basics [YouTube Video]. In <em>YouTube</em>. <a href="https://www.youtube.com/watch?v=prZMpThbU3E">https://www.youtube.com/watch?v=prZMpThbU3E</a>
</div>
<div id="ref-MCMC_Ritvik2021" class="csl-entry">
ritvikmath. (2021b). Markov chain monte carlo (MCMC) : Data science concepts [YouTube Video]. In <em>YouTube</em>. <a href="https://www.youtube.com/watch?v=yApmR-c_hKU">https://www.youtube.com/watch?v=yApmR-c_hKU</a>
</div>
<div id="ref-Robert2007" class="csl-entry">
Robert, C. P. (2007). <em>The bayesian choice: From decision-theoretic foundations to computational implementation</em> (2nd ed., p. 615) [Book]. Springer. <a href="https://doi.org/10.1007/0-387-71599-1">https://doi.org/10.1007/0-387-71599-1</a>
</div>
<div id="ref-Vehtari2022" class="csl-entry">
Vehtari, A., Gabry, J., &amp; Goodrich, B. (2022). <em>Bayesian logistic regression with rstanarm</em> [Web Page]. Aki Vehtari: Model Selection. <a href="https://avehtari.github.io/modelselection/diabetes.html">https://avehtari.github.io/modelselection/diabetes.html</a>
</div>
<div id="ref-deVille2013" class="csl-entry">
Ville, B. de. (2013). <em>WIREs Computational Statistics</em>, <em>5</em>(6), 448–455. https://doi.org/<a href="https://doi.org/10.1002/wics.1278">https://doi.org/10.1002/wics.1278</a>
</div>
<div id="ref-ibm" class="csl-entry">
What is a decision tree. (n.d.). In <em>IBM</em>. IBM. Retrieved November 30, 2022, from <a href="https://www.ibm.com/topics/decision-trees">https://www.ibm.com/topics/decision-trees</a>
</div>
<div id="ref-Winter2021" class="csl-entry">
Winter, B., &amp; Bürkner, P.-C. (2021). Poisson regression for linguists: A tutorial introduction to modelling count data with brms. <em>Language and Linguistics Compass</em>, <em>15</em>(11), e12439. https://doi.org/<a href="https://doi.org/10.1111/lnc3.12439">https://doi.org/10.1111/lnc3.12439</a>
</div>
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="supervised-learning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
